{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Complete Intersection Calabi-Yau 3-folds\n",
    "\n",
    "Harold Erbin and Riccardo Finotello\n",
    "\n",
    "_Physics Department_\n",
    "\n",
    "_Universit√† degli Studi di Torino and I.N.F.N. - sezione di Torino_\n",
    "\n",
    "_via Pietro Giuria 1, I-10125 Torino, Italy_\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "In this notebook we prepare the original dataset ([1]-[2]) and the favourable dataset ([3]) for the analysis: we download the tarballs, extract them and tidy the datasets.\n",
    "\n",
    "- [1]: P. Candelas, A. M. Dale, C. A. Lutken and R. Schimmrigk, \"Complete Intersection Calabi-Yau Manifolds\", Nucl. Phys. B 298 (1988)\n",
    "- [2]: P. S. Green, T. Hubsch and C. A. Lutken, \"All Hodge Numbers of All Complete Intersection Calabi-Yau Manifolds\", Class. Quant. Grav. 6 (1989)\n",
    "- [3]: L. B. Anderson, X. Gao, J. Gray and S. J. Lee, \"Fibrations in CICY Threefolds\", JHEP 10 (2017), arXiv:1708.07907."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the Datasets\n",
    "\n",
    "In this section we download the tarballs and load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "# create a directory to store the datasets\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "\n",
    "# download the files\n",
    "file_o_url = 'http://www.lpthe.jussieu.fr/~erbin/files/data/cicy3o_data.tar.gz'\n",
    "file_f_url = 'http://www.lpthe.jussieu.fr/~erbin/files/data/cicy3f_data.tar.gz'\n",
    "\n",
    "file_o_out = './data/cicy3o_data.tar.gz'\n",
    "file_f_out = './data/cicy3f_data.tar.gz'\n",
    "\n",
    "if not os.path.isfile(file_o_out):\n",
    "    urllib.request.urlretrieve(file_o_url, file_o_out)\n",
    "\n",
    "if not os.path.isfile(file_f_out):\n",
    "    urllib.request.urlretrieve(file_f_url, file_f_out)\n",
    "    \n",
    "# open the tarballs\n",
    "if os.path.isfile(file_o_out):\n",
    "    with tarfile.open(file_o_out, 'r') as tar:\n",
    "        tar.extract('cicy3o.h5', './data')\n",
    "        \n",
    "if os.path.isfile(file_f_out):\n",
    "    with tarfile.open(file_f_out, 'r') as tar:\n",
    "        tar.extract('cicy3f.h5', './data')\n",
    "        \n",
    "# load the dataset\n",
    "df_o = pd.read_hdf('./data/cicy3o.h5')\n",
    "df_f = pd.read_hdf('./data/cicy3f.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are composed by the following columns and dtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7890 entries, 1 to 7890\n",
      "Data columns (total 31 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   c2              7890 non-null   object \n",
      " 1   euler           7890 non-null   int16  \n",
      " 2   h11             7890 non-null   int16  \n",
      " 3   h21             7890 non-null   int16  \n",
      " 4   matrix          7890 non-null   object \n",
      " 5   redun           7890 non-null   object \n",
      " 6   size            7890 non-null   object \n",
      " 7   num_cp          7890 non-null   int8   \n",
      " 8   num_eqs         7890 non-null   int64  \n",
      " 9   dim_cp          7890 non-null   object \n",
      " 10  min_dim_cp      7890 non-null   int64  \n",
      " 11  max_dim_cp      7890 non-null   int64  \n",
      " 12  mean_dim_cp     7890 non-null   float64\n",
      " 13  median_dim_cp   7890 non-null   float64\n",
      " 14  num_dim_cp      7890 non-null   object \n",
      " 15  num_cp_1        7890 non-null   int8   \n",
      " 16  num_cp_2        7890 non-null   int8   \n",
      " 17  num_cp_neq1     7890 non-null   int8   \n",
      " 18  num_over        7890 non-null   int8   \n",
      " 19  num_ex          7890 non-null   int8   \n",
      " 20  deg_eqs         7890 non-null   object \n",
      " 21  min_deg_eqs     7890 non-null   int64  \n",
      " 22  max_deg_eqs     7890 non-null   int64  \n",
      " 23  mean_deg_eqs    7890 non-null   float64\n",
      " 24  median_deg_eqs  7890 non-null   float64\n",
      " 25  num_deg_eqs     7890 non-null   object \n",
      " 26  rank_matrix     7890 non-null   int8   \n",
      " 27  norm_matrix     7890 non-null   float64\n",
      " 28  dim_h0_amb      7890 non-null   object \n",
      " 29  isprod          7890 non-null   int64  \n",
      " 30  favour          7890 non-null   int64  \n",
      "dtypes: float64(5), int16(3), int64(7), int8(7), object(9)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_o.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7890 entries, 1 to 7890\n",
      "Data columns (total 31 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   c2              7890 non-null   object \n",
      " 1   favour          7890 non-null   int64  \n",
      " 2   h11             7890 non-null   int16  \n",
      " 3   h21             7890 non-null   int16  \n",
      " 4   isprod          7890 non-null   int64  \n",
      " 5   kahlerpos       7890 non-null   int64  \n",
      " 6   matrix          7890 non-null   object \n",
      " 7   size            7890 non-null   object \n",
      " 8   euler           7890 non-null   int16  \n",
      " 9   num_cp          7890 non-null   int8   \n",
      " 10  num_eqs         7890 non-null   int64  \n",
      " 11  dim_cp          7890 non-null   object \n",
      " 12  min_dim_cp      7890 non-null   int64  \n",
      " 13  max_dim_cp      7890 non-null   int64  \n",
      " 14  mean_dim_cp     7890 non-null   float64\n",
      " 15  median_dim_cp   7890 non-null   float64\n",
      " 16  num_dim_cp      7890 non-null   object \n",
      " 17  num_cp_1        7890 non-null   int8   \n",
      " 18  num_cp_2        7890 non-null   int8   \n",
      " 19  num_cp_neq1     7890 non-null   int8   \n",
      " 20  num_over        7890 non-null   int8   \n",
      " 21  num_ex          7890 non-null   int8   \n",
      " 22  deg_eqs         7890 non-null   object \n",
      " 23  min_deg_eqs     7890 non-null   int64  \n",
      " 24  max_deg_eqs     7890 non-null   int64  \n",
      " 25  mean_deg_eqs    7890 non-null   float64\n",
      " 26  median_deg_eqs  7890 non-null   float64\n",
      " 27  num_deg_eqs     7890 non-null   object \n",
      " 28  rank_matrix     7890 non-null   int8   \n",
      " 29  norm_matrix     7890 non-null   float64\n",
      " 30  dim_h0_amb      7890 non-null   object \n",
      "dtypes: float64(5), int16(3), int64(8), int8(7), object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_f.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tydy Datasets\n",
    "\n",
    "To better handle the dataset, we extract each _object_ column into a dense format and create one unique variable (column) for each entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_series(series: pd.Series) -> pd.Series:\n",
    "    '''\n",
    "    Extract a Pandas series into its dense format.\n",
    "    \n",
    "    Required arguments:\n",
    "        series: the pandas series.\n",
    "        \n",
    "    Returns:\n",
    "        the pandas series in dense format.\n",
    "    '''\n",
    "    # avoid direct overwriting\n",
    "    series = series.copy()\n",
    "    \n",
    "    # cget the maximum size of each axis\n",
    "    max_shape = series.apply(np.shape).max()\n",
    "    \n",
    "    # return the transformed series\n",
    "    if np.prod(max_shape) > 1:\n",
    "        # compute the necessary shift and apply it\n",
    "        offset = lambda s: [(0, max_shape[i] - np.shape(s)[i])\n",
    "                            for i in range(len(max_shape))\n",
    "                           ]\n",
    "        return series.apply(lambda s: np.pad(s, offset(s), mode='constant'))\n",
    "    else:\n",
    "        return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply it to all variables of the dataset \n",
    "df_o = df_o.apply(extract_series)\n",
    "df_f = df_f.apply(extract_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then save the shape of all variables to be able to access them later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape_o = df_o.applymap(np.shape).apply(np.unique).to_dict(orient='records')[0]\n",
    "df_shape_f = df_f.applymap(np.shape).apply(np.unique).to_dict(orient='records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/cicy3o_shapes.json', 'w') as o:\n",
    "    json.dump(df_shape_o, o)\n",
    "\n",
    "with open('./data/cicy3f_shapes.json', 'w') as f:\n",
    "    json.dump(df_shape_f, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a new dataframe holding each entry of the _object_ features in a separate variable to be able to separately handle each entry (since we already know that all entries are numeric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_variables(series: pd.Series) -> pd.DataFrame:\n",
    "    '''\n",
    "    Take one variable and explode its components in a new column.\n",
    "    \n",
    "    Required arguments:\n",
    "        series: the variable to explode.\n",
    "        \n",
    "    Returns:\n",
    "        a dataframe containing one observable for each column.\n",
    "    '''\n",
    "    # avoid direct overwriting\n",
    "    series = series.copy()\n",
    "    \n",
    "    if series.apply(lambda x: np.prod(np.shape(x))).max() == 1:\n",
    "        return series\n",
    "    else:\n",
    "        # flatten the array\n",
    "        series = series.apply(lambda x: np.reshape(x, (-1,)))\n",
    "\n",
    "        # explode over columns\n",
    "        series = series.apply(pd.Series).rename(columns=lambda x: series.name + '_{}'.format(x+1))\n",
    "\n",
    "        return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the order of the columns\n",
    "column_list = ['h11', 'h21', 'euler',\n",
    "               'c2', 'size', 'isprod', 'favour',\n",
    "               'num_cp', 'num_eqs',\n",
    "               'dim_h0_amb',\n",
    "               'dim_cp', 'num_dim_cp',\n",
    "               'min_dim_cp', 'max_dim_cp', 'mean_dim_cp', 'median_dim_cp',\n",
    "               'num_cp_1', 'num_cp_2', 'num_cp_neq1',\n",
    "               'num_over', 'num_ex',\n",
    "               'deg_eqs', 'num_deg_eqs',\n",
    "               'min_deg_eqs', 'max_deg_eqs', 'mean_deg_eqs', 'median_deg_eqs',\n",
    "               'rank_matrix', 'norm_matrix',\n",
    "               'matrix' \n",
    "              ]\n",
    "\n",
    "# create a new data frame and \"left join\" each new variable\n",
    "df_o_tmp = pd.DataFrame(index=df_o.index)\n",
    "for var in column_list:\n",
    "    df_o_tmp = df_o_tmp.join(explode_variables(df_o[var]))\n",
    "    \n",
    "df_f_tmp = pd.DataFrame(index=df_f.index)\n",
    "for var in column_list:\n",
    "    df_f_tmp = df_f_tmp.join(explode_variables(df_f[var]))\n",
    "    \n",
    "# overwrite the old files\n",
    "df_o = df_o_tmp\n",
    "df_f = df_f_tmp\n",
    "\n",
    "del df_o_tmp, df_f_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for duplicates in rows (all variables must coincide):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum     0.0\n",
       "mean    0.0\n",
       "Name: dup_o, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_o.duplicated().rename('dup_o').agg({'sum', 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum     0.0\n",
       "mean    0.0\n",
       "Name: dup_f, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.duplicated().rename('dup_f').agg({'sum', 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new datasets to a separate CSV files for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o.to_csv('./data/cicy3o_tidy.csv', index=False)\n",
    "df_f.to_csv('./data/cicy3f_tidy.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
