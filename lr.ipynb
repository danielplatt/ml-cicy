{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "We compute a prediction baseline using linear regression for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Dataset\n",
    "\n",
    "We first download and unzip the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, tarfile, os\n",
    "\n",
    "file_url = 'http://www.lpthe.jussieu.fr/~erbin/files/data/cicy3o_data.tar.gz'\n",
    "file_out = './cicy3o.tar.gz'\n",
    "file_dat = 'cicy3o.h5'\n",
    "\n",
    "if not os.path.isfile(file_out):\n",
    "    urllib.request.urlretrieve(file_url, file_out)\n",
    "    \n",
    "if not os.path.isfile(file_dat):\n",
    "    with tarfile.open(file_out, 'r') as tar:\n",
    "        tar.extract(file_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "We then load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dat = pd.read_hdf(os.path.join('.', file_dat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the outliers (keep $h^{1,1} \\in [1, 16]$ and $h^{2,1} \\in [15, 86]$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_out   = dat\n",
    "dat_noout = dat.loc[(dat['h11'] > 0) &\n",
    "                    (dat['h11'] < 17) &\n",
    "                    (dat['h21'] > 14) &\n",
    "                    (dat['h21'] < 87)\n",
    "                   ]\n",
    "\n",
    "dat_out   = dat_out[['h11', 'h21', 'matrix']]\n",
    "dat_noout = dat_noout[['h11', 'h21', 'matrix']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then extract the `matrix` column into its dense format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_series(series: pd.Series) -> pd.Series:\n",
    "    '''\n",
    "    Extract a Pandas series into its dense format.\n",
    "    \n",
    "    Required arguments:\n",
    "        series: the pandas series.\n",
    "        \n",
    "    Returns:\n",
    "        the pandas series in dense format.\n",
    "    '''\n",
    "    # avoid direct overwriting\n",
    "    series = series.copy()\n",
    "    \n",
    "    # cget the maximum size of each axis\n",
    "    max_shape = series.apply(np.shape).max()\n",
    "    \n",
    "    # return the transformed series\n",
    "    if np.prod(max_shape) > 1:\n",
    "        # compute the necessary shift and apply it\n",
    "        offset = lambda s: [(0, max_shape[i] - np.shape(s)[i])\n",
    "                            for i in range(len(max_shape))\n",
    "                           ]\n",
    "        return series.apply(lambda s: np.pad(s, offset(s), mode='constant'))\n",
    "    else:\n",
    "        return series\n",
    "    \n",
    "# apply it to the matrix\n",
    "dat_out   = dat_out.apply(extract_series)\n",
    "dat_noout = dat_noout.apply(extract_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Strategy\n",
    "\n",
    "We then subsample the set into training, validation and test sets for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    Training set w/ outliers:   80.00%\n",
      "    Test set w/ outliers:       20.00%\n",
      "\n",
      "    Training set w/o outliers:   79.99%\n",
      "    Test set w/o outliers:       20.01%\n",
      "\n",
      "30% training data:\n",
      "    Training set w/ outliers:   30.00%\n",
      "    Test set w/ outliers:       70.00%\n",
      "\n",
      "    Training set w/o outliers:   30.00%\n",
      "    Test set w/o outliers:       70.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set random state\n",
    "RAND = 42\n",
    "np.random.seed(RAND)\n",
    "\n",
    "# split training set\n",
    "dat_out_train_80,   dat_out_test_80   = train_test_split(dat_out, train_size=0.8, shuffle=True, random_state=RAND)\n",
    "dat_out_train_30,   dat_out_test_30   = train_test_split(dat_out, train_size=0.3, shuffle=True, random_state=RAND)\n",
    "dat_noout_train_80, dat_noout_test_80 = train_test_split(dat_noout, train_size=0.8, shuffle=True, random_state=RAND)\n",
    "dat_noout_train_30, dat_noout_test_30 = train_test_split(dat_noout, train_size=0.3, shuffle=True, random_state=RAND)\n",
    "\n",
    "# check sizes\n",
    "print('80% training data:')\n",
    "print('    Training set w/ outliers:   {:.2f}%'.format(100 * dat_out_train_80.shape[0] / dat_out.shape[0]))\n",
    "print('    Test set w/ outliers:       {:.2f}%'.format(100 * dat_out_test_80.shape[0] / dat_out.shape[0]))\n",
    "print('')\n",
    "print('    Training set w/o outliers:   {:.2f}%'.format(100 * dat_noout_train_80.shape[0] / dat_noout.shape[0]))\n",
    "print('    Test set w/o outliers:       {:.2f}%'.format(100 * dat_noout_test_80.shape[0] / dat_noout.shape[0]))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    Training set w/ outliers:   {:.2f}%'.format(100 * dat_out_train_30.shape[0] / dat_out.shape[0]))\n",
    "print('    Test set w/ outliers:       {:.2f}%'.format(100 * dat_out_test_30.shape[0] / dat_out.shape[0]))\n",
    "print('')\n",
    "print('    Training set w/o outliers:   {:.2f}%'.format(100 * dat_noout_train_30.shape[0] / dat_noout.shape[0]))\n",
    "print('    Test set w/o outliers:       {:.2f}%'.format(100 * dat_noout_test_30.shape[0] / dat_noout.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix\n",
    "mat_out_train_80   = np.array(dat_out_train_80['matrix'].tolist()).reshape(-1,180)\n",
    "mat_noout_train_80 = np.array(dat_noout_train_80['matrix'].tolist()).reshape(-1,180)\n",
    "mat_out_train_30   = np.array(dat_out_train_30['matrix'].tolist()).reshape(-1,180)\n",
    "mat_noout_train_30 = np.array(dat_noout_train_30['matrix'].tolist()).reshape(-1,180)\n",
    "\n",
    "mat_out_test_80    = np.array(dat_out_test_80['matrix'].tolist()).reshape(-1,180)\n",
    "mat_noout_test_80  = np.array(dat_noout_test_80['matrix'].tolist()).reshape(-1,180)\n",
    "mat_out_test_30    = np.array(dat_out_test_30['matrix'].tolist()).reshape(-1,180)\n",
    "mat_noout_test_30  = np.array(dat_noout_test_30['matrix'].tolist()).reshape(-1,180)\n",
    "\n",
    "# labels\n",
    "lab_out_train_80 = {'h11_output': dat_out_train_80['h11'].values.reshape(-1,),\n",
    "                    'h21_output': dat_out_train_80['h21'].values.reshape(-1,)\n",
    "                   }\n",
    "lab_noout_train_80 = {'h11_output': dat_noout_train_80['h11'].values.reshape(-1,),\n",
    "                      'h21_output': dat_noout_train_80['h21'].values.reshape(-1,)\n",
    "                     }\n",
    "lab_out_train_30 = {'h11_output': dat_out_train_30['h11'].values.reshape(-1,),\n",
    "                    'h21_output': dat_out_train_30['h21'].values.reshape(-1,)\n",
    "                   }\n",
    "lab_noout_train_30 = {'h11_output': dat_noout_train_30['h11'].values.reshape(-1,),\n",
    "                      'h21_output': dat_noout_train_30['h21'].values.reshape(-1,)\n",
    "                     }\n",
    "\n",
    "lab_out_test_80   = {'h11_output': dat_out_test_80['h11'].values.reshape(-1,),\n",
    "                     'h21_output': dat_out_test_80['h21'].values.reshape(-1,)\n",
    "                    }\n",
    "lab_noout_test_80   = {'h11_output': dat_noout_test_80['h11'].values.reshape(-1,),\n",
    "                       'h21_output': dat_noout_test_80['h21'].values.reshape(-1,)\n",
    "                      }\n",
    "lab_out_test_30   = {'h11_output': dat_out_test_30['h11'].values.reshape(-1,),\n",
    "                     'h21_output': dat_out_test_30['h21'].values.reshape(-1,)\n",
    "                    }\n",
    "lab_noout_test_30   = {'h11_output': dat_noout_test_30['h11'].values.reshape(-1,),\n",
    "                       'h21_output': dat_noout_test_30['h21'].values.reshape(-1,)\n",
    "                      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression ($\\ell_1$ regularised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    Accuracy on h_11 w/  outliers: 48.10%\n",
      "    Accuracy on h_21 w/  outliers: 10.71%\n",
      "    Accuracy on h_11 w/o outliers: 50.60%\n",
      "    Accuracy on h_21 w/o outliers: 9.17%\n",
      "\n",
      "30% training data:\n",
      "    Accuracy on h_11 w/  outliers: 47.67%\n",
      "    Accuracy on h_21 w/  outliers: 9.92%\n",
      "    Accuracy on h_11 w/o outliers: 49.05%\n",
      "    Accuracy on h_21 w/o outliers: 9.52%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# define the estimators\n",
    "lr_out_80   = MultiOutputRegressor(Lasso(alpha=2.0e-4, fit_intercept=False, max_iter=1e5, random_state=RAND), n_jobs=-1)\n",
    "lr_noout_80 = MultiOutputRegressor(Lasso(alpha=2.0e-4, fit_intercept=False, max_iter=1e5, random_state=RAND), n_jobs=-1)\n",
    "lr_out_30   = MultiOutputRegressor(Lasso(alpha=2.0e-4, fit_intercept=False, max_iter=1e5, random_state=RAND), n_jobs=-1)\n",
    "lr_noout_30 = MultiOutputRegressor(Lasso(alpha=2.0e-4, fit_intercept=False, max_iter=1e5, random_state=RAND), n_jobs=-1)\n",
    "\n",
    "# train the estimators\n",
    "lr_out_80.fit(mat_out_train_80, pd.DataFrame(lab_out_train_80).values)\n",
    "lr_noout_80.fit(mat_noout_train_80, pd.DataFrame(lab_noout_train_80).values)\n",
    "lr_out_30.fit(mat_out_train_30, pd.DataFrame(lab_out_train_30).values)\n",
    "lr_noout_30.fit(mat_noout_train_30, pd.DataFrame(lab_noout_train_30).values)\n",
    "\n",
    "# compute the predictions\n",
    "pred_out_80   = np.floor(lr_out_80.predict(mat_out_test_80)).astype(int)\n",
    "pred_noout_80 = np.floor(lr_noout_80.predict(mat_noout_test_80)).astype(int)\n",
    "pred_out_30   = np.floor(lr_out_30.predict(mat_out_test_30)).astype(int)\n",
    "pred_noout_30 = np.floor(lr_noout_30.predict(mat_noout_test_30)).astype(int)\n",
    "\n",
    "# save predictions to file\n",
    "pd.DataFrame({'h11_pred': pred_out_80[:,0],\n",
    "              'h11_true': lab_out_test_80['h11_output'],\n",
    "              'h21_pred': pred_out_80[:,1],\n",
    "              'h21_true': lab_out_test_80['h21_output']\n",
    "             }\n",
    "            ).to_csv('./dat/svm_out_80.csv')\n",
    "pd.DataFrame({'h11_pred': pred_noout_80[:,0],\n",
    "              'h11_true': lab_noout_test_80['h11_output'],\n",
    "              'h21_pred': pred_noout_80[:,1],\n",
    "              'h21_true': lab_noout_test_80['h21_output']\n",
    "             }\n",
    "            ).to_csv('./dat/svm_noout_80.csv')\n",
    "pd.DataFrame({'h11_pred': pred_out_30[:,0],\n",
    "              'h11_true': lab_out_test_30['h11_output'],\n",
    "              'h21_pred': pred_out_30[:,1],\n",
    "              'h21_true': lab_out_test_30['h21_output']\n",
    "             }\n",
    "            ).to_csv('./dat/svm_out_30.csv')\n",
    "pd.DataFrame({'h11_pred': pred_noout_30[:,0],\n",
    "              'h11_true': lab_noout_test_30['h11_output'],\n",
    "              'h21_pred': pred_noout_30[:,1],\n",
    "              'h21_true': lab_noout_test_30['h21_output']\n",
    "             }\n",
    "            ).to_csv('./dat/svm_noout_30.csv')\n",
    "\n",
    "# compute accuracy\n",
    "h11_acc_out_80   = np.mean((lab_out_test_80['h11_output'] == pred_out_80[:,0]).astype(int))\n",
    "h21_acc_out_80   = np.mean((lab_out_test_80['h21_output'] == pred_out_80[:,1]).astype(int))\n",
    "h11_acc_noout_80 = np.mean((lab_noout_test_80['h11_output'] == pred_noout_80[:,0]).astype(int))\n",
    "h21_acc_noout_80 = np.mean((lab_noout_test_80['h21_output'] == pred_noout_80[:,1]).astype(int))\n",
    "h11_acc_out_30   = np.mean((lab_out_test_30['h11_output'] == pred_out_30[:,0]).astype(int))\n",
    "h21_acc_out_30   = np.mean((lab_out_test_30['h21_output'] == pred_out_30[:,1]).astype(int))\n",
    "h11_acc_noout_30 = np.mean((lab_noout_test_30['h11_output'] == pred_noout_30[:,0]).astype(int))\n",
    "h21_acc_noout_30 = np.mean((lab_noout_test_30['h21_output'] == pred_noout_30[:,1]).astype(int))\n",
    "\n",
    "# print accuracy\n",
    "print('80% training data:')\n",
    "print('    Accuracy on h_11 w/  outliers: {:.2f}%'.format(100 * h11_acc_out_80))\n",
    "print('    Accuracy on h_21 w/  outliers: {:.2f}%'.format(100 * h21_acc_out_80))\n",
    "print('    Accuracy on h_11 w/o outliers: {:.2f}%'.format(100 * h11_acc_noout_80))\n",
    "print('    Accuracy on h_21 w/o outliers: {:.2f}%'.format(100 * h21_acc_noout_80))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    Accuracy on h_11 w/  outliers: {:.2f}%'.format(100 * h11_acc_out_30))\n",
    "print('    Accuracy on h_21 w/  outliers: {:.2f}%'.format(100 * h21_acc_out_30))\n",
    "print('    Accuracy on h_11 w/o outliers: {:.2f}%'.format(100 * h11_acc_noout_30))\n",
    "print('    Accuracy on h_21 w/o outliers: {:.2f}%'.format(100 * h21_acc_noout_30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
