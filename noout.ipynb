{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set memory growth (necessary for training)\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./cicy3o_tidy.csv')\n",
    "\n",
    "# remove the outliers completely\n",
    "df = df.loc[(df['h11'] >= 1) &\n",
    "            (df['h11'] <= 16) &\n",
    "            (df['h21'] >= 15) &\n",
    "            (df['h21'] <= 86)\n",
    "           ].reset_index(drop=True)\n",
    "\n",
    "# select the matrix to compute the PCA\n",
    "mat = df.filter(regex='^matrix_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.99).fit_transform(mat)\n",
    "col = ['pca_{}'.format(n) for n in range(pca.shape[1])]\n",
    "\n",
    "pca = pd.DataFrame(pca, columns=col)\n",
    "\n",
    "df  = df.join(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_entry = mat.max().max()\n",
    "mat = mat / max_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h11 = df.filter(regex='^num_cp$|^dim_cp|^pca').values\n",
    "df_h21 = df.filter(regex='^num_cp$|^dim_cp|^dim_h0|^pca').values\n",
    "\n",
    "df_nopca_h11 = df.filter(regex='^num_cp$|^dim_cp').values\n",
    "df_nopca_h21 = df.filter(regex='^num_cp$|^dim_cp|^dim_h0').values\n",
    "\n",
    "h11    = df['h11'].values.reshape(-1,)\n",
    "h21    = df['h21'].values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_h11_train_80, df_h11_test_80, \\\n",
    "df_h21_train_80, df_h21_test_80, \\\n",
    "df_nopca_h11_train_80, df_nopca_h11_test_80, \\\n",
    "df_nopca_h21_train_80, df_nopca_h21_test_80, \\\n",
    "mat_train_80, mat_test_80, \\\n",
    "h11_train_80, h11_test_80, \\\n",
    "h21_train_80, h21_test_80 = train_test_split(df_h11, df_h21, df_nopca_h11, df_nopca_h21, mat, h11, h21,\n",
    "                                             train_size=0.8, shuffle=True, random_state=RAND)\n",
    "\n",
    "df_h11_train_30, df_h11_test_30, \\\n",
    "df_h21_train_30, df_h21_test_30, \\\n",
    "df_nopca_h11_train_30, df_nopca_h11_test_30, \\\n",
    "df_nopca_h21_train_30, df_nopca_h21_test_30, \\\n",
    "mat_train_30, mat_test_30, \\\n",
    "h11_train_30, h11_test_30, \\\n",
    "h21_train_30, h21_test_30 = train_test_split(df_h11, df_h21, df_nopca_h11, df_nopca_h21, mat, h11, h21,\n",
    "                                             train_size=0.3, shuffle=True, random_state=RAND)\n",
    "\n",
    "mat_val_80, mat_test_80, \\\n",
    "h11_cnn_val_80, h11_cnn_test_80, \\\n",
    "h21_cnn_val_80, h21_cnn_test_80 = train_test_split(mat_test_80, h11_test_80, h21_test_80,\n",
    "                                                   train_size=1/2, shuffle=True, random_state=RAND\n",
    "                                                  )\n",
    "\n",
    "mat_val_30, mat_test_30, \\\n",
    "h11_cnn_val_30, h11_cnn_test_30, \\\n",
    "h21_cnn_val_30, h21_cnn_test_30 = train_test_split(mat_test_30, h11_test_30, h21_test_30,\n",
    "                                                   train_size=1/7, shuffle=True, random_state=RAND\n",
    "                                                  )\n",
    "\n",
    "mat_train_80 = mat_train_80.values.reshape(-1, 12, 15, 1)\n",
    "mat_train_30 = mat_train_30.values.reshape(-1, 12, 15, 1)\n",
    "mat_val_80   = mat_val_80.values.reshape(-1, 12, 15, 1)\n",
    "mat_val_30   = mat_val_30.values.reshape(-1, 12, 15, 1)\n",
    "mat_test_80  = mat_test_80.values.reshape(-1, 12, 15, 1)\n",
    "mat_test_30  = mat_test_30.values.reshape(-1, 12, 15, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression (PCA + eng. feat.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    h11 accuracy: 0.637\n",
      "    h21 accuracy: 0.202\n",
      "\n",
      "30% training data:\n",
      "    h11 accuracy: 0.625\n",
      "    h21 accuracy: 0.193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "est_h11_80 = Lasso(alpha=0.07, fit_intercept=False, max_iter=1e6, random_state=RAND)\n",
    "est_h21_80 = Lasso(alpha=2.0e-6, fit_intercept=True, normalize=True, max_iter=1e6, random_state=RAND)\n",
    "est_h11_30 = Lasso(alpha=0.07, fit_intercept=False, max_iter=1e6, random_state=RAND)\n",
    "est_h21_30 = Lasso(alpha=2.0e-6, fit_intercept=True, normalize=True, max_iter=1e6, random_state=RAND)\n",
    "\n",
    "est_h11_80.fit(df_h11_train_80, h11_train_80)\n",
    "est_h21_80.fit(df_h21_train_80, h21_train_80)\n",
    "est_h11_30.fit(df_h11_train_30, h11_train_30)\n",
    "est_h21_30.fit(df_h21_train_30, h21_train_30)\n",
    "\n",
    "h11_pred_80 = np.floor(est_h11_80.predict(df_h11_test_80)).astype(int)\n",
    "h21_pred_80 = np.floor(est_h21_80.predict(df_h21_test_80)).astype(int)\n",
    "h11_pred_30 = np.floor(est_h11_30.predict(df_h11_test_30)).astype(int)\n",
    "h21_pred_30 = np.floor(est_h21_30.predict(df_h21_test_30)).astype(int)\n",
    "\n",
    "print('\\nLINEAR REGRESSION')\n",
    "print('80% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_80, h11_pred_80)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_80, h21_pred_80)))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_30, h11_pred_30)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_30, h21_pred_30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM (eng. feat.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/conda/envs/ml4cicy/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    h11 accuracy: 0.630\n",
      "    h21 accuracy: 0.183\n",
      "\n",
      "30% training data:\n",
      "    h11 accuracy: 0.626\n",
      "    h21 accuracy: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/conda/envs/ml4cicy/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "est_h11_80 = LinearSVR(C=0.13, epsilon=0.9, fit_intercept=True, intercept_scaling=0.01, loss='epsilon_insensitive', max_iter=1e6, random_state=RAND)\n",
    "est_h21_80 = LinearSVR(C=0.51, epsilon=0.0, fit_intercept=True, intercept_scaling=100, loss='epsilon_insensitive', max_iter=1e6, random_state=RAND)\n",
    "est_h11_30 = LinearSVR(C=0.13, epsilon=0.9, fit_intercept=True, intercept_scaling=0.01, loss='epsilon_insensitive', max_iter=1e6, random_state=RAND)\n",
    "est_h21_30 = LinearSVR(C=0.51, epsilon=0.0, fit_intercept=True, intercept_scaling=100, loss='epsilon_insensitive', max_iter=1e6, random_state=RAND)\n",
    "\n",
    "est_h11_80.fit(df_nopca_h11_train_80, h11_train_80)\n",
    "est_h21_80.fit(df_nopca_h21_train_80, h21_train_80)\n",
    "est_h11_30.fit(df_nopca_h11_train_30, h11_train_30)\n",
    "est_h21_30.fit(df_nopca_h21_train_30, h21_train_30)\n",
    "\n",
    "h11_pred_80 = np.floor(est_h11_80.predict(df_nopca_h11_test_80)).astype(int)\n",
    "h21_pred_80 = np.floor(est_h21_80.predict(df_nopca_h21_test_80)).astype(int)\n",
    "h11_pred_30 = np.floor(est_h11_30.predict(df_nopca_h11_test_30)).astype(int)\n",
    "h21_pred_30 = np.floor(est_h21_30.predict(df_nopca_h21_test_30)).astype(int)\n",
    "\n",
    "print('\\nLINEAR SVM')\n",
    "print('80% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_80, h11_pred_80)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_80, h21_pred_80)))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_30, h11_pred_30)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_30, h21_pred_30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian SVM (PCA + eng. feat.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    h11 accuracy: 0.716\n",
      "    h21 accuracy: 0.337\n",
      "\n",
      "30% training data:\n",
      "    h11 accuracy: 0.693\n",
      "    h21 accuracy: 0.272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "est_h11_80 = SVR(C=1.0, epsilon=0.02, gamma=0.02)\n",
    "est_h21_80 = SVR(C=45, epsilon=0.2, gamma=0.013)\n",
    "est_h11_30 = SVR(C=1.0, epsilon=0.02, gamma=0.02)\n",
    "est_h21_30 = SVR(C=45, epsilon=0.2, gamma=0.013)\n",
    "\n",
    "est_h11_80.fit(df_h11_train_80, h11_train_80)\n",
    "est_h21_80.fit(df_h21_train_80, h21_train_80)\n",
    "est_h11_30.fit(df_h11_train_30, h11_train_30)\n",
    "est_h21_30.fit(df_h21_train_30, h21_train_30)\n",
    "\n",
    "h11_pred_80 = np.rint(est_h11_80.predict(df_h11_test_80)).astype(int)\n",
    "h21_pred_80 = np.rint(est_h21_80.predict(df_h21_test_80)).astype(int)\n",
    "h11_pred_30 = np.rint(est_h11_30.predict(df_h11_test_30)).astype(int)\n",
    "h21_pred_30 = np.rint(est_h21_30.predict(df_h21_test_30)).astype(int)\n",
    "\n",
    "print('\\nGAUSSIAN SVM')\n",
    "print('80% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_80, h11_pred_80)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_80, h21_pred_80)))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_30, h11_pred_30)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_30, h21_pred_30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (PCA + eng. feat.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    h11 accuracy: 0.627\n",
      "    h21 accuracy: 0.164\n",
      "\n",
      "30% training data:\n",
      "    h11 accuracy: 0.584\n",
      "    h21 accuracy: 0.144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "est_h11_80 = RandomForestRegressor(criterion='mae',\n",
    "                                   max_depth=30,\n",
    "                                   max_leaf_nodes=90,\n",
    "                                   min_samples_leaf=1,\n",
    "                                   min_samples_split=100,\n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   n_estimators=10,\n",
    "                                   random_state=RAND,\n",
    "                                   n_jobs=-1\n",
    "                                  )\n",
    "est_h21_80 = RandomForestRegressor(criterion='mae',\n",
    "                                   max_depth=100,\n",
    "                                   max_leaf_nodes=100,\n",
    "                                   min_samples_leaf=30,\n",
    "                                   min_samples_split=2,\n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   n_estimators=300,\n",
    "                                   random_state=RAND,\n",
    "                                   n_jobs=-1\n",
    "                                  )\n",
    "est_h11_30 = RandomForestRegressor(criterion='mae',\n",
    "                                   max_depth=30,\n",
    "                                   max_leaf_nodes=90,\n",
    "                                   min_samples_leaf=1,\n",
    "                                   min_samples_split=100,\n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   n_estimators=10,\n",
    "                                   random_state=RAND,\n",
    "                                   n_jobs=-1\n",
    "                                  )\n",
    "est_h21_30 = RandomForestRegressor(criterion='mae',\n",
    "                                   max_depth=100,\n",
    "                                   max_leaf_nodes=100,\n",
    "                                   min_samples_leaf=30,\n",
    "                                   min_samples_split=2,\n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   n_estimators=300,\n",
    "                                   random_state=RAND,\n",
    "                                   n_jobs=-1\n",
    "                                  )\n",
    "\n",
    "est_h11_80.fit(df_h11_train_80, h11_train_80)\n",
    "est_h21_80.fit(df_h21_train_80, h21_train_80)\n",
    "est_h11_30.fit(df_h11_train_30, h11_train_30)\n",
    "est_h21_30.fit(df_h21_train_30, h21_train_30)\n",
    "\n",
    "h11_pred_80 = np.floor(est_h11_80.predict(df_h11_test_80)).astype(int)\n",
    "h21_pred_80 = np.floor(est_h21_80.predict(df_h21_test_80)).astype(int)\n",
    "h11_pred_30 = np.floor(est_h11_30.predict(df_h11_test_30)).astype(int)\n",
    "h21_pred_30 = np.floor(est_h21_30.predict(df_h21_test_30)).astype(int)\n",
    "\n",
    "print('\\nRANDOM FOREST')\n",
    "print('80% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_80, h11_pred_80)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_80, h21_pred_80)))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_30, h11_pred_30)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_30, h21_pred_30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting (eng. feat.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    h11 accuracy: 0.569\n",
      "    h21 accuracy: 0.232\n",
      "\n",
      "30% training data:\n",
      "    h11 accuracy: 0.554\n",
      "    h21 accuracy: 0.201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "est_h11_80 = GradientBoostingRegressor(criterion='friedman_mse',\n",
    "                                       learning_rate=0.15,\n",
    "                                       loss='ls',\n",
    "                                       max_depth=2,\n",
    "                                       min_samples_split=10,\n",
    "                                       min_weight_fraction_leaf=0.2,\n",
    "                                       n_estimators=100,\n",
    "                                       subsample=0.1,\n",
    "                                       random_state=RAND\n",
    "                                      )\n",
    "est_h21_80 = GradientBoostingRegressor(criterion='mae',\n",
    "                                       learning_rate=0.04,\n",
    "                                       loss='huber',\n",
    "                                       alpha=0.99,\n",
    "                                       max_depth=35,\n",
    "                                       min_samples_split=2,\n",
    "                                       min_weight_fraction_leaf=0.0,\n",
    "                                       n_estimators=200,\n",
    "                                       subsample=0.1,\n",
    "                                       random_state=RAND\n",
    "                                      )\n",
    "est_h11_30 = GradientBoostingRegressor(criterion='friedman_mse',\n",
    "                                       learning_rate=0.15,\n",
    "                                       loss='ls',\n",
    "                                       max_depth=2,\n",
    "                                       min_samples_split=10,\n",
    "                                       min_weight_fraction_leaf=0.2,\n",
    "                                       n_estimators=100,\n",
    "                                       subsample=0.1,\n",
    "                                       random_state=RAND\n",
    "                                      )\n",
    "est_h21_30 = GradientBoostingRegressor(criterion='mae',\n",
    "                                       learning_rate=0.04,\n",
    "                                       loss='huber',\n",
    "                                       alpha=0.99,\n",
    "                                       max_depth=35,\n",
    "                                       min_samples_split=2,\n",
    "                                       min_weight_fraction_leaf=0.0,\n",
    "                                       n_estimators=200,\n",
    "                                       subsample=0.1,\n",
    "                                       random_state=RAND\n",
    "                                      )\n",
    "\n",
    "est_h11_80.fit(df_nopca_h11_train_80, h11_train_80)\n",
    "est_h21_80.fit(df_nopca_h21_train_80, h21_train_80)\n",
    "est_h11_30.fit(df_nopca_h11_train_30, h11_train_30)\n",
    "est_h21_30.fit(df_nopca_h21_train_30, h21_train_30)\n",
    "\n",
    "h11_pred_80 = np.floor(est_h11_80.predict(df_nopca_h11_test_80)).astype(int)\n",
    "h21_pred_80 = np.floor(est_h21_80.predict(df_nopca_h21_test_80)).astype(int)\n",
    "h11_pred_30 = np.floor(est_h11_30.predict(df_nopca_h11_test_30)).astype(int)\n",
    "h21_pred_30 = np.floor(est_h21_30.predict(df_nopca_h21_test_30)).astype(int)\n",
    "\n",
    "print('\\nGRADIENT BOOSTING')\n",
    "print('80% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_80, h11_pred_80)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_80, h21_pred_80)))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_test_30, h11_pred_30)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_test_30, h21_pred_30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet (matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and discard previous weights\n",
    "convnet = tf.keras.models.load_model('./cnn_sequential.h5')\n",
    "convnet_h11_80 = tf.keras.models.model_from_json(convnet.to_json())\n",
    "convnet_h21_80 = tf.keras.models.model_from_json(convnet.to_json())\n",
    "convnet_h11_30 = tf.keras.models.model_from_json(convnet.to_json())\n",
    "convnet_h21_30 = tf.keras.models.model_from_json(convnet.to_json())\n",
    "\n",
    "convnet_h11_80.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                       loss='mse',\n",
    "                       metrics=['mse', 'mae']\n",
    "                      )\n",
    "convnet_h21_80.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                       loss='mse',\n",
    "                       metrics=['mse', 'mae']\n",
    "                      )\n",
    "convnet_h11_30.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                       loss='mse',\n",
    "                       metrics=['mse', 'mae']\n",
    "                      )\n",
    "convnet_h21_30.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                       loss='mse',\n",
    "                       metrics=['mse', 'mae']\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbaks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                 factor=0.3,\n",
    "                                                 patience=80,\n",
    "                                                 verbose=0,\n",
    "                                                 min_lr=1.0e-6\n",
    "                                                ),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                             patience=200,\n",
    "                                             verbose=0,\n",
    "                                             restore_best_weights=True\n",
    "                                            )\n",
    "           ]\n",
    "\n",
    "_ = convnet_h11_80.fit(x=mat_train_80,\n",
    "                       y=h11_train_80,\n",
    "                       batch_size=32,\n",
    "                       epochs=10,\n",
    "                       verbose=0,\n",
    "                       callbacks=callbaks,\n",
    "                       validation_data=(mat_val_80, h11_cnn_val_80)\n",
    "                      )\n",
    "_ = convnet_h21_80.fit(x=mat_train_80,\n",
    "                       y=h21_train_80,\n",
    "                       batch_size=32,\n",
    "                       epochs=10,\n",
    "                       verbose=0,\n",
    "                       callbacks=callbaks,\n",
    "                       validation_data=(mat_val_80, h21_cnn_val_80)\n",
    "                      )\n",
    "_ = convnet_h11_30.fit(x=mat_train_30,\n",
    "                       y=h11_train_30,\n",
    "                       batch_size=32,\n",
    "                       epochs=10,\n",
    "                       verbose=0,\n",
    "                       callbacks=callbaks,\n",
    "                       validation_data=(mat_val_30, h11_cnn_val_30)\n",
    "                      )\n",
    "_ = convnet_h21_30.fit(x=mat_train_30,\n",
    "                       y=h21_train_30,\n",
    "                       batch_size=32,\n",
    "                       epochs=10,\n",
    "                       verbose=0,\n",
    "                       callbacks=callbaks,\n",
    "                       validation_data=(mat_val_30, h21_cnn_val_30)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    h11 accuracy: 0.814\n",
      "    h21 accuracy: 0.248\n",
      "\n",
      "30% training data:\n",
      "    h11 accuracy: 0.621\n",
      "    h21 accuracy: 0.214\n"
     ]
    }
   ],
   "source": [
    "h11_cnn_pred_80 = np.rint(convnet_h11_80.predict(mat_test_80).reshape(-1,)).astype(int)\n",
    "h21_cnn_pred_80 = np.rint(convnet_h21_80.predict(mat_test_80).reshape(-1,)).astype(int)\n",
    "h11_cnn_pred_30 = np.rint(convnet_h11_30.predict(mat_test_30).reshape(-1,)).astype(int)\n",
    "h21_cnn_pred_30 = np.rint(convnet_h21_30.predict(mat_test_30).reshape(-1,)).astype(int)\n",
    "\n",
    "print('\\nCONVNET')\n",
    "print('80% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_cnn_test_80, h11_cnn_pred_80)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_cnn_test_80, h21_cnn_pred_80)))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_cnn_test_30, h11_cnn_pred_30)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_cnn_test_30, h21_cnn_pred_30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception (matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and discard previous weights\n",
    "inception = tf.keras.models.load_model('./cnn_inception.h5')\n",
    "inception_h11_80 = tf.keras.models.model_from_json(inception.to_json())\n",
    "inception_h21_80 = tf.keras.models.model_from_json(inception.to_json())\n",
    "inception_h11_30 = tf.keras.models.model_from_json(inception.to_json())\n",
    "inception_h21_30 = tf.keras.models.model_from_json(inception.to_json())\n",
    "\n",
    "inception_h11_80.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                         loss='mse',\n",
    "                         metrics=['mse', 'mae']\n",
    "                        )\n",
    "inception_h21_80.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                         loss='mse',\n",
    "                         metrics=['mse', 'mae']\n",
    "                        )\n",
    "inception_h11_30.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                         loss='mse',\n",
    "                         metrics=['mse', 'mae']\n",
    "                        )\n",
    "inception_h21_30.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                         loss='mse',\n",
    "                         metrics=['mse', 'mae']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbaks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                 factor=0.3,\n",
    "                                                 patience=75,\n",
    "                                                 verbose=0,\n",
    "                                                 min_lr=1.0e-6\n",
    "                                                ),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                             patience=200,\n",
    "                                             verbose=0,\n",
    "                                             restore_best_weights=True\n",
    "                                            )\n",
    "           ]\n",
    "\n",
    "_ = inception_h11_80.fit(x=mat_train_80,\n",
    "                         y=h11_train_80,\n",
    "                         batch_size=32,\n",
    "                         epochs=10,\n",
    "                         verbose=0,\n",
    "                         callbacks=callbaks,\n",
    "                         validation_data=(mat_val_80, h11_cnn_val_80)\n",
    "                        )\n",
    "_ = inception_h21_80.fit(x=mat_train_80,\n",
    "                         y=h21_train_80,\n",
    "                         batch_size=32,\n",
    "                         epochs=10,\n",
    "                         verbose=0,\n",
    "                         callbacks=callbaks,\n",
    "                         validation_data=(mat_val_80, h21_cnn_val_80)\n",
    "                        )\n",
    "_ = inception_h11_30.fit(x=mat_train_30,\n",
    "                         y=h11_train_30,\n",
    "                         batch_size=32,\n",
    "                         epochs=10,\n",
    "                         verbose=0,\n",
    "                         callbacks=callbaks,\n",
    "                         validation_data=(mat_val_30, h11_cnn_val_30)\n",
    "                        )\n",
    "_ = inception_h21_30.fit(x=mat_train_30,\n",
    "                         y=h21_train_30,\n",
    "                         batch_size=32,\n",
    "                         epochs=10,\n",
    "                         verbose=0,\n",
    "                         callbacks=callbaks,\n",
    "                         validation_data=(mat_val_30, h21_cnn_val_30)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    h11 accuracy: 0.644\n",
      "    h21 accuracy: 0.190\n",
      "\n",
      "30% training data:\n",
      "    h11 accuracy: 0.538\n",
      "    h21 accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "h11_cnn_pred_80 = np.rint(inception_h11_80.predict(mat_test_80).reshape(-1,)).astype(int)\n",
    "h21_cnn_pred_80 = np.rint(inception_h21_80.predict(mat_test_80).reshape(-1,)).astype(int)\n",
    "h11_cnn_pred_30 = np.rint(inception_h11_30.predict(mat_test_30).reshape(-1,)).astype(int)\n",
    "h21_cnn_pred_30 = np.rint(inception_h21_30.predict(mat_test_30).reshape(-1,)).astype(int)\n",
    "\n",
    "print('\\nINCEPTION')\n",
    "print('80% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_cnn_test_80, h11_cnn_pred_80)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_cnn_test_80, h21_cnn_pred_80)))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    h11 accuracy: {:.3f}'.format(accuracy_score(h11_cnn_test_30, h11_cnn_pred_30)))\n",
    "print('    h21 accuracy: {:.3f}'.format(accuracy_score(h21_cnn_test_30, h21_cnn_pred_30)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
