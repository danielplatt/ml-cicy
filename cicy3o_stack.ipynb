{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Complete Intersection Calabi-Yau Manifolds\n",
    "\n",
    "In order to improve the results of the analysis, we employ the _stacking_ procedure to improve the predictions on $h_{11}$ and $h_{21}$. This is an **ensemble** learning technique typically used in competitions. We use:\n",
    "\n",
    "- [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) to see whether **L1** and **L2** can be implemented together,\n",
    "- [SVR (with Gaussian kernel)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) to introduce a kernel function,\n",
    "- [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor) to use forests of **decision trees** for the predictions,\n",
    "- Inception-like neural network,\n",
    "\n",
    "on a first level training set to have predictions on a second level set. We then use a second level (or **meta**) estimator, such as:\n",
    "\n",
    "- [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "\n",
    "on the new predictions.\n",
    "\n",
    "For this analysis we use the feature engineered dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infrastructure\n",
    "\n",
    "We print information about the current OS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current OS:                  Linux (kernel release: 5.6.12-arch1-1, architecture: x86_64)\n",
      "Number of available threads: 8\n",
      "Current CPU frequency:       2865 MHz (max: 3800 MHz)\n",
      "Available RAM memory:        5979 MB (tot: 15758 MB)\n"
     ]
    }
   ],
   "source": [
    "from mltools.libos import InfoOS\n",
    "\n",
    "print('Current OS:                  {} (kernel release: {}, architecture: {})'.format(InfoOS().os, InfoOS().kernel, InfoOS().arch))\n",
    "print('Number of available threads: {:d}'.format(InfoOS().threads))\n",
    "print('Current CPU frequency:       {:.0f} MHz (max: {:.0f} MHz)'.format(InfoOS().freq, InfoOS().freqm))\n",
    "print('Available RAM memory:        {:d} MB (tot: {:d} MB)'.format(InfoOS().vmav, InfoOS().vmtot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future use, we establish early in the notebook the number of maximum jobs that every algorithm can take concurrently. Thus, if we want to run parallel notebooks with different jobs, we will not encounter issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_jobs = int(InfoOS().threads) #---------- very intensive but faster\n",
    "#n_jobs = int(InfoOS().threads / 2) #------ still fast enough but less intensive (only 50% of available threads are occupied)\n",
    "n_jobs = int(InfoOS().threads / 4) #------ slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then print information on the current GPU setup (if available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 19 09:39:08 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce 940MX       Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   66C    P8    N/A /  N/A |      5MiB /  2004MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0   1400850      G   /usr/lib/Xorg                                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We import the Python modules we use and print their versions to keep track of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7\n",
      "Matplot version: 3.2.1\n",
      "Numpy version: 1.18.4\n",
      "Pandas version: 1.0.3\n",
      "Scikit-learn version: 0.22.2.post1\n",
      "Scikit-optimize version: 0.7.4\n",
      "Tensorflow version: 2.0.0\n",
      "Keras version: 2.2.4-tf (backend: tensorflow)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import random     as rnd\n",
    "import sklearn    as skl\n",
    "import skopt      as sko\n",
    "import numpy      as np\n",
    "import pandas     as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow       import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning) # ignore user warnings: nothing that I can really do anything about it...\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=12)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# print the version of the modules\n",
    "print('Python version: {:d}.{:d}'      .format(sys.version_info.major, sys.version_info.minor))\n",
    "print('Matplot version: {}'            .format(mpl.__version__))\n",
    "print('Numpy version: {}'              .format(np.__version__))\n",
    "print('Pandas version: {}'             .format(pd.__version__))\n",
    "print('Scikit-learn version: {}'       .format(skl.__version__))\n",
    "print('Scikit-optimize version: {}'    .format(sko.__version__))\n",
    "print('Tensorflow version: {}'         .format(tf.__version__))\n",
    "print('Keras version: {} (backend: {})'.format(keras.__version__, K.backend()))\n",
    "\n",
    "# fix random_seed\n",
    "RAND = 42\n",
    "rnd.seed(RAND)\n",
    "np.random.seed(RAND)\n",
    "tf.random.set_seed(RAND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Preparation\n",
    "\n",
    "in order to save the results of the analysis, we define where to store images, log files and models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "\n",
    "ROOT_DIR = '.' #-------------------------------------------------- root directory\n",
    "IMG_DIR  = 'img' #------------------------------------------------ directory of images\n",
    "MOD_DIR  = 'models' #--------------------------------------------- directory of saved models\n",
    "LOG_DIR  = 'log' #------------------------------------------------ directory of logs\n",
    "\n",
    "DB_NAME = 'cicy3o' #---------------------------------------------- name of the dataset\n",
    "DB_FILE = DB_NAME + '_analysis.h5' #------------------------------ full name with extension\n",
    "DB_PATH = path.join(ROOT_DIR, DB_FILE) #-------------------------- full path of the dataset\n",
    "DB_DIR  = 'original' if DB_NAME == 'cicy3o' else 'favourable' #--- subdir where to store images, models, logs\n",
    "\n",
    "# define full paths\n",
    "IMG_PATH = path.join(ROOT_DIR, IMG_DIR, DB_DIR)\n",
    "MOD_PATH = path.join(ROOT_DIR, MOD_DIR, DB_DIR)\n",
    "LOG_PATH = path.join(ROOT_DIR, LOG_DIR, DB_DIR)\n",
    "\n",
    "# create directories if non existent\n",
    "if not path.isdir(IMG_PATH):\n",
    "    makedirs(IMG_PATH, exist_ok=True)\n",
    "if not path.isdir(MOD_PATH):\n",
    "    makedirs(MOD_PATH, exist_ok=True)\n",
    "if not path.isdir(LOG_PATH):\n",
    "    makedirs(LOG_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a log file to store debug and related information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotating existing logs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 09:39:11,516: INFO ==> New logging session started. Log is at ./log/original/cicy3o_stack.log.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from mltools.liblog import create_logfile\n",
    "\n",
    "path_to_log = path.join(LOG_PATH,\n",
    "                        DB_NAME + '_stack.log'\n",
    "                       )\n",
    "log = create_logfile(path_to_log,\n",
    "                     name=DB_NAME + '_stack',\n",
    "                     level=logging.DEBUG\n",
    "                    )\n",
    "\n",
    "# these lines provide the same setup also for the Jupyter logging\n",
    "logger = logging.getLogger() #------------------------------------------------- get the current logging session\n",
    "\n",
    "fmt = logging.Formatter('%(asctime)s: %(levelname)s ==> %(message)s') #-------- customise the formatting options\n",
    "\n",
    "handler = logging.StreamHandler() #-------------------------------------------- handle the stream to the default (stderr)\n",
    "handler.setLevel(logging.DEBUG) #---------------------------------------------- print everything\n",
    "handler.setFormatter(fmt) #---------------------------------------------------- set the formatting options\n",
    "\n",
    "logger.handlers = [handler] #-------------------------------------------------- override the default stream\n",
    "\n",
    "# we are ready to go!\n",
    "log.info('New logging session started. Log is at {}.'.format(path_to_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally set the _memory growth_ property of the GPU in order to avoid overflowing its RAM memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU setup: 1 physical GPUs, 1 logical GPUs.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU') #--------------------------------------- list of physical GPUs\n",
    "\n",
    "if gpus: #----------------------------------------------------------------------------------------- set memory growth only if GPU is active\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True) #---------------------------------- set memory growth\n",
    "            \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU') #------------------------ list of logical devices\n",
    "        print('GPU setup: {:d} physical GPUs, {:d} logical GPUs.'.format(len(gpus),\n",
    "                                                                         len(logical_gpus)\n",
    "                                                                        )\n",
    "             )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPUs in the setup!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "We first load the dataset we built during the preanalysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 09:39:12,159: DEBUG ==> Database loaded.\n",
      "2020-05-19 09:39:12,160: INFO ==> Shape is 7851 rows x 7 columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "if path.isfile(DB_PATH):\n",
    "    df = pd.read_hdf(DB_PATH)\n",
    "    log.debug('Database loaded.')\n",
    "    log.info('Shape is {:d} rows x {:d} columns.'.format(df.shape[0], df.shape[1]))\n",
    "else:\n",
    "    log.error('Cannot load database from {}!'.format(DB_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the `dtypes` and the name of the keys inside the dataframe as a reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h11            int16\n",
       "h21            int16\n",
       "num_cp          int8\n",
       "dim_cp        object\n",
       "dim_h0_amb    object\n",
       "matrix        object\n",
       "pca           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Format Extraction\n",
    "\n",
    "We now extract the needed features from the sparse format in which they are stores. We also contextually build the feature matrices and the labels vectors needed in the analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.libtransformer import ExtractTensor\n",
    "\n",
    "# extract the labels\n",
    "h11        = df['h11'].values\n",
    "h21        = df['h21'].values\n",
    "\n",
    "# extract the scalar feature\n",
    "num_cp     = np.reshape(df['num_cp'].values, (-1,1)) #------------------------------- num_cp needs to be reshaped because it is a single feature\n",
    "\n",
    "# extract the vector features\n",
    "dim_cp     = np.array(ExtractTensor(flatten=True).fit_transform(df['dim_cp']))\n",
    "dim_h0_amb = np.array(ExtractTensor(flatten=True).fit_transform(df['dim_h0_amb']))\n",
    "\n",
    "# extract the PCA\n",
    "pca        = np.array(ExtractTensor(flatten=True).fit_transform(df['pca']))\n",
    "\n",
    "# extract the matrix\n",
    "matrix = np.array(ExtractTensor(flatten=False).fit_transform(df['matrix'])) #-------- old shape is (batch, width, height)\n",
    "matrix = np.reshape(matrix, (-1, np.shape(matrix)[1], np.shape(matrix)[2], 1)) #----- new shape is (batch, width, height, 1)\n",
    "\n",
    "# build the feature engineered sets\n",
    "feat_h11 = np.c_[num_cp, dim_cp, pca]\n",
    "feat_h21 = np.c_[num_cp, dim_cp, dim_h0_amb, pca]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Strategy\n",
    "\n",
    "We will split the original **full** training set (90% of the total dataset) in two levels (50% of it each) and train the first level estimator on it (using **cross-validation** with 5 splits, such that roughly 9% of the total training set will be used for validation each time). We then keep the final 10% of the dataset as test set. We use Bayesan optimization (from the [_Scikit-optimize_](https://scikit-optimize.github.io/stable/index.html) library) of the hyperparameters as it helps in finding a \"direction\" in the procedure (as opposed to a random search) and avoids useless grid searches which for large hyperparameter spaces are unfeasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 09:39:16,041: DEBUG ==> Train set size (lv.1): 3532\n",
      "2020-05-19 09:39:16,045: DEBUG ==> Train set size (lv.2): 3533\n",
      "2020-05-19 09:39:16,050: DEBUG ==> Test set size: 786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# define the cross-validation splits\n",
    "cv = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# divide into training and test sets\n",
    "feat_h11_train, feat_h11_test, \\\n",
    "feat_h21_train, feat_h21_test, \\\n",
    "matrix_train, matrix_test, \\\n",
    "h11_train, h11_test, \\\n",
    "h21_train, h21_test = train_test_split(feat_h11, feat_h21, matrix, h11, h21,\n",
    "                                       test_size=0.1,\n",
    "                                       shuffle=False\n",
    "                                      )\n",
    "\n",
    "# split the dataset into two branches\n",
    "feat_h11_train_lv1, feat_h11_train_lv2, \\\n",
    "feat_h21_train_lv1, feat_h21_train_lv2, \\\n",
    "matrix_train_lv1, matrix_train_lv2, \\\n",
    "h11_train_lv1, h11_train_lv2, \\\n",
    "h21_train_lv1, h21_train_lv2 = train_test_split(feat_h11_train, feat_h21_train, matrix_train, h11_train, h21_train,\n",
    "                                                test_size=0.5,\n",
    "                                                shuffle=False\n",
    "                                               )\n",
    "\n",
    "# keep a development set for the matrix at lv1\n",
    "matrix_train_lv1, matrix_val_lv1, \\\n",
    "h11_matrix_train_lv1, h11_matrix_val_lv1, \\\n",
    "h21_matrix_train_lv1, h21_matrix_val_lv1 = train_test_split(matrix_train_lv1, h11_train_lv1, h21_train_lv1,\n",
    "                                                            test_size=0.2,\n",
    "                                                            shuffle=False)\n",
    "\n",
    "# rescale the matrix\n",
    "scale_factor     = np.max(matrix_train_lv1) - np.min(matrix_train_lv1)\n",
    "matrix_train_lv1 = matrix_train_lv1 / scale_factor\n",
    "matrix_val_lv1   = matrix_val_lv1 / scale_factor\n",
    "matrix_train_lv2 = matrix_train_lv2 / scale_factor\n",
    "matrix_test      = matrix_test / scale_factor\n",
    "\n",
    "# debug info\n",
    "log.debug('Train set size (lv.1): {:d}'.format(np.shape(feat_h11_train_lv1)[0]))\n",
    "log.debug('Train set size (lv.2): {:d}'.format(np.shape(feat_h11_train_lv2)[0]))\n",
    "log.debug('Test set size: {:d}'.format(np.shape(feat_h11_test)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the analysis that follows we will then study the accuracy of the algorithms both on validation and test sets and we will plot the predictions made by each algorithm. We will also clearly print the best fitting hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty(dct, indent=True):\n",
    "    '''\n",
    "    Pretty print the dictionary of best parameters.\n",
    "    \n",
    "    Required argument:\n",
    "        dct:    the dictionary to pretty print.\n",
    "        \n",
    "    Optional argument:\n",
    "        indent: whether to indent the printed output.\n",
    "    '''\n",
    "    \n",
    "    for key, value in dct.items():\n",
    "        if indent:\n",
    "            print('    {} = {}'.format(key, value))\n",
    "        else:\n",
    "            print('{} = {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Level Training\n",
    "\n",
    "First of all we train the algorithms on the first level training set and produce the predictions for the second level and the test predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Elastic Net](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)\n",
    "\n",
    "We start by training an elastic net which implements both **L1** and **L2** regularization. The additional term to the cost function is $\\Delta J(\\theta) = \\alpha L_1 \\vert\\vert \\theta \\vert\\vert + \\frac{1}{2} \\alpha (1 - L_1) \\vert\\vert \\theta \\vert\\vert^2$. In the same way, we could have written $\\Delta J(\\theta) = a \\vert\\vert \\theta \\vert\\vert + b \\vert\\vert  \\theta \\vert\\vert^2$ where $\\alpha = a + b$ and $L_1 = \\frac{a}{a + b}$. The hyperparameters we control are:\n",
    "\n",
    "- `fit_intercept` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `normalize` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `positive` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `alpha` $\\in \\left[ 10^{-6}, 10^{-1} \\right]$,\n",
    "- `l1_ratio` $\\in \\left[ 0, 1 \\right]$ (the $L_1$ in the previous formulae),\n",
    "- `selection` $\\in \\lbrace random, cyclic \\rbrace$ (controls whether to update coefficients randomly or looping through the features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 09:39:16,123: INFO ==> Trainining elastic net...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for h11:\n",
      "\n",
      "    alpha = 0.09991472046372592\n",
      "    fit_intercept = 0\n",
      "    l1_ratio = 0.856532553497912\n",
      "    normalize = 0\n",
      "    positive = 0\n",
      "    selection = random\n",
      "\n",
      "Accuracy of the cross-validation: 62.401% ± 1.584%\n",
      "Accuracy of the predictions: 64.758%\n",
      "\n",
      "Best parameters for h21:\n",
      "\n",
      "    alpha = 2.7714892835448284e-05\n",
      "    fit_intercept = 1\n",
      "    l1_ratio = 1.0\n",
      "    normalize = 1\n",
      "    positive = 0\n",
      "    selection = random\n",
      "\n",
      "Accuracy of the cross-validation: 20.243% ± 1.807%\n",
      "Accuracy of the predictions: 18.830%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 09:52:33,637: DEBUG ==> Plot saved to ./img/original/el_net_lv1_error.pdf.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from skopt                import BayesSearchCV\n",
    "from skopt.space          import Integer, Real, Categorical\n",
    "from sklearn.metrics      import make_scorer\n",
    "from mltools.libscore     import accuracy, Score, ViewCV\n",
    "from mltools.libplot      import Plot\n",
    "\n",
    "log.info('Trainining elastic net...')\n",
    "\n",
    "rounding      = np.floor #----------------------------------------------------------------- choose a rounding function\n",
    "n_iter        = 50 #----------------------------------------------------------------------- the number of iteration of the Bayes search\n",
    "search_params = {'fit_intercept': Integer(0, 1),\n",
    "                 'normalize':     Integer(0, 1),\n",
    "                 'positive':      Integer(0, 1),\n",
    "                 'l1_ratio':      Real(0.0,    1.0,    prior='uniform'),\n",
    "                 'alpha':         Real(1.0e-6, 1.0e-1, prior='log-uniform'),\n",
    "                 'selection':     Categorical(['random', 'cyclic'])\n",
    "                } #------------------------------------------------------------------------ define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(ElasticNet(max_iter=1e4, tol=1.0e-2, random_state=RAND), #--- choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #--------------------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "estimator.fit(feat_h11_train_lv1, h11_train_lv1) #----------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "el_net_preds_h11 = estimator.best_estimator_.predict(feat_h11_train_lv2) #----------------------- compute predictions for h11 (lv2)\n",
    "el_net_test_preds_h11 = estimator.best_estimator_.predict(feat_h11_test) #----------------------- compute predictions for h11 (test)\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=el_net_test_preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_train_lv1, h21_train_lv1) #----------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "el_net_preds_h21 = estimator.best_estimator_.predict(feat_h21_train_lv2) #----------------------- compute predictions for h21 (lv2)\n",
    "el_net_test_preds_h21 = estimator.best_estimator_.predict(feat_h21_test) #----------------------- compute predictions for h21 (test)\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=el_net_test_preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=1) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'el_net_lv1_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'el_net_lv1_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)\n",
    "\n",
    "We then consider the **support vector machine**. The hyperparameter space is:\n",
    "\n",
    "- `gamma` $\\in \\left[ 10^{-3}, 10^3 \\right]$,\n",
    "- `epsilon` $\\in \\left[ 10^{-2}, 10^2 \\right]$ (the $\\epsilon$ parameter for the penalty computation),\n",
    "- `C` $\\in \\left[ 1, 10^3 \\right]$ (the regularization parameter),\n",
    "- `shrinking` $\\in \\lbrace 0, 1 \\rbrace$ (whether to use shrinking heuristic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 09:52:33,663: INFO ==> Trainining svr (Gaussian kernel)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for h11:\n",
      "\n",
      "    C = 1.0\n",
      "    epsilon = 0.025057196524195666\n",
      "    gamma = 0.023235058181806986\n",
      "    shrinking = 1\n",
      "\n",
      "Accuracy of the cross-validation: 69.281% ± 1.320%\n",
      "Accuracy of the predictions: 70.102%\n",
      "\n",
      "Best parameters for h21:\n",
      "\n",
      "    C = 1000.0\n",
      "    epsilon = 0.09403057259501005\n",
      "    gamma = 0.001\n",
      "    shrinking = 0\n",
      "\n",
      "Accuracy of the cross-validation: 30.181% ± 0.607%\n",
      "Accuracy of the predictions: 30.280%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 10:19:01,155: DEBUG ==> Plot saved to ./img/original/svr_lv1_error.pdf.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm      import SVR\n",
    "from skopt            import BayesSearchCV\n",
    "from skopt.space      import Integer, Real, Categorical\n",
    "from sklearn.metrics  import make_scorer\n",
    "from mltools.libscore import accuracy, Score, ViewCV\n",
    "from mltools.libplot  import Plot\n",
    "\n",
    "log.info('Trainining svr (Gaussian kernel)...')\n",
    "\n",
    "rounding      = np.rint #---------------------------------------------------------- choose a rounding function\n",
    "n_iter        = 50 #--------------------------------------------------------------- the number of iteration of the Bayes search\n",
    "search_params = {'shrinking': Integer(0, 1),\n",
    "                 'epsilon':   Real(1.0e-2, 1.0e2, prior='log-uniform'),\n",
    "                 'C':         Real(1.0e0, 1.0e3,  prior='log-uniform'),\n",
    "                 'gamma':     Real(1.0e-3, 1.0e3, prior='log-uniform')\n",
    "                } #---------------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(SVR(kernel='rbf', max_iter=1e5), #------------------- choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #------------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "estimator.fit(feat_h11_train_lv1, h11_train_lv1) #----------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "svr_rbf_preds_h11   = estimator.best_estimator_.predict(feat_h11_train_lv2) #-------------------- compute predictions for h11 (lv2)\n",
    "svr_rbf_test_preds_h11   = estimator.best_estimator_.predict(feat_h11_test) #-------------------- compute predictions for h11 (test)\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=svr_rbf_test_preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_train_lv1, h21_train_lv1) #----------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "svr_rbf_preds_h21   = estimator.best_estimator_.predict(feat_h21_train_lv2) #-------------------- compute predictions for h21 (lv2)\n",
    "svr_rbf_test_preds_h21   = estimator.best_estimator_.predict(feat_h21_test) #-------------------- compute predictions for h21 (test)\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=svr_rbf_test_preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=1) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'svr_lv1_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'svr_lv1_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "\n",
    "We then move to a different kind of decision tree algorithm and train a random forest of trees on the dataset.  In this case the hyperparameter space we explore is:\n",
    "\n",
    "- `n_estimators` $\\in \\left[ 5, 75 \\right]$,\n",
    "- `criterion` $\\in \\lbrace mse, mae \\rbrace$,\n",
    "- `max_depth` $\\in \\left[ 2, 100 \\right]$,\n",
    "- `min_samples_split` $\\in \\left[ 2, 100 \\right]$,\n",
    "- `min_samples_leaf` $\\in \\left[ 1, 100 \\right]$,\n",
    "- `min_weight_fraction_leaf` $\\in \\left[ 0, \\frac{1}{2} \\right]$,\n",
    "- `max_leaf_nodes` $\\in \\left[ 2, 100 \\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 10:19:01,174: INFO ==> Trainining random forest...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for h11:\n",
      "\n",
      "    criterion = mae\n",
      "    max_depth = 50\n",
      "    max_leaf_nodes = 61\n",
      "    min_samples_leaf = 1\n",
      "    min_samples_split = 2\n",
      "    min_weight_fraction_leaf = 0.0\n",
      "    n_estimators = 75\n",
      "\n",
      "Accuracy of the cross-validation: 62.174% ± 0.792%\n",
      "Accuracy of the predictions: 61.323%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from skopt            import BayesSearchCV\n",
    "from skopt.space      import Integer, Real, Categorical\n",
    "from sklearn.metrics  import make_scorer\n",
    "from mltools.libscore import accuracy, Score, ViewCV\n",
    "from mltools.libplot  import Plot\n",
    "\n",
    "log.info('Trainining random forest...')\n",
    "\n",
    "rounding      = np.floor #------------------------------------------------------------------- choose a rounding function\n",
    "n_iter        = 20 #------------------------------------------------------------------------- the number of iteration of the Bayes search\n",
    "search_params = {'n_estimators':             Integer(5, 75,  prior='uniform'),\n",
    "                 'max_depth':                Integer(2, 100, prior='uniform'),\n",
    "                 'min_samples_split':        Integer(2, 100, prior='uniform'),\n",
    "                 'min_samples_leaf':         Integer(1, 100, prior='uniform'),\n",
    "                 'max_leaf_nodes':           Integer(2, 100, prior='uniform'),\n",
    "                 'min_weight_fraction_leaf': Real(0.0, 0.5, prior='uniform'),\n",
    "                 'criterion':                Categorical(['mse', 'mae'])\n",
    "                } #-------------------------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(RandomForestRegressor(random_state=RAND), #-------------------- choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #----------------------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "estimator.fit(feat_h11_train_lv1, h11_train_lv1) #----------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "rnd_for_preds_h11   = estimator.best_estimator_.predict(feat_h11_train_lv2) #-------------------- compute predictions for h11 (lv2)\n",
    "rnd_for_test_preds_h11   = estimator.best_estimator_.predict(feat_h11_test) #-------------------- compute predictions for h11 (test)\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=rnd_for_test_preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_train_lv1, h21_train_lv1) #----------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "rnd_for_preds_h21   = estimator.best_estimator_.predict(feat_h21_train_lv2) #-------------------- compute predictions for h21 (lv2)\n",
    "rnd_for_test_preds_h21   = estimator.best_estimator_.predict(feat_h21_test) #-------------------- compute predictions for h21 (test)\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=rnd_for_test_preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=1) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'rnd_for_lv1_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'rnd_for_lv1_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "We import the models using the _inception-like_ architecture and let them train (we start from the weights used in the training for the complete set: at worst they are sufficiently asymmetric to provide a good initialization and at best they can speed up the training process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models    import load_model\n",
    "from tensorflow.keras.backend   import clear_session\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from mltools.libscore           import Score\n",
    "\n",
    "# define a function to fit the model with the correct callbacks, etc.\n",
    "def cnn_fit(model,\n",
    "            X,\n",
    "            y,\n",
    "            X_val,\n",
    "            y_val,\n",
    "            batch_size=32,\n",
    "            epochs=100,\n",
    "            early_stopping=10,\n",
    "            reduce_lr=5,\n",
    "            verbose=0\n",
    "           ):\n",
    "    '''\n",
    "    Fit the model.\n",
    "    \n",
    "    Required arguments:\n",
    "        model:          the model to fit,\n",
    "        X:              the training features,\n",
    "        y:              the training labels,\n",
    "        X_val:          the validation features,\n",
    "        y_val:          the validation labels.\n",
    "        \n",
    "    Optional arguments:\n",
    "        batch_size:     the size of the batch used in forward pass,\n",
    "        epochs:         the number of epochs,\n",
    "        early_stopping: patience of early stopping,\n",
    "        reduce_lr:      patience to reduce learning rate,\n",
    "        verbose:        verbosity level (debug)\n",
    "    \n",
    "    Returns:\n",
    "        the fitted model, the history of the model.\n",
    "    '''\n",
    "    \n",
    "    # clear the TF graph\n",
    "    clear_session()\n",
    "    \n",
    "    # define callbacks\n",
    "    callbacks = [EarlyStopping(monitor='val_mean_squared_error',\n",
    "                               patience=early_stopping,\n",
    "                               verbose=verbose,\n",
    "                               restore_best_weights=True\n",
    "                              ),\n",
    "                 ReduceLROnPlateau(monitor='val_mean_squared_error',\n",
    "                                   factor=0.3,\n",
    "                                   patience=reduce_lr,\n",
    "                                   verbose=verbose\n",
    "                                  ),\n",
    "                 ModelCheckpoint(filepath=path.join(MOD_PATH, model.name + '_stack.h5'),\n",
    "                                 monitor='val_mean_squared_error',\n",
    "                                 verbose=verbose,\n",
    "                                 save_best_only=True,\n",
    "                                 save_format='h5'\n",
    "                                )\n",
    "                ]\n",
    "    \n",
    "    # fit the model\n",
    "    history = model.fit(x=X,\n",
    "                        y=y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=verbose,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=(X_val, y_val)\n",
    "                       )\n",
    "    \n",
    "    # return the fitted model and its history\n",
    "    return model, history.history\n",
    "\n",
    "# load the models\n",
    "if path.isfile(path.join(MOD_PATH, 'h11_same_conv_no_fc.h5')):\n",
    "    network_h11 = load_model(path.join(MOD_PATH, 'h11_same_conv_no_fc.h5'))\n",
    "else:\n",
    "    log.error('Cannot load model for h11!')\n",
    "    \n",
    "if path.isfile(path.join(MOD_PATH, 'h21_same_conv_no_fc.h5')):\n",
    "    network_h21 = load_model(path.join(MOD_PATH, 'h21_same_conv_no_fc.h5'))\n",
    "else:\n",
    "    log.error('Cannot load model for h21!')\n",
    "    \n",
    "# fit the models\n",
    "log.info('Fitting the model for h11...')\n",
    "h11_model, h11_model_history = cnn_fit(network_h11,\n",
    "                                       matrix_train_lv1,\n",
    "                                       h11_matrix_train_lv1,\n",
    "                                       matrix_val_lv1,\n",
    "                                       h11_matrix_val_lv1,\n",
    "                                       batch_size=32,\n",
    "                                       epochs=100,\n",
    "                                       early_stopping=10,\n",
    "                                       reduce_lr=5,\n",
    "                                       verbose=0\n",
    "                                      )\n",
    "h11_model_predictions      = h11_model.predict(matrix_train_lv2)\n",
    "h11_model_test_predictions = h11_model.predict(matrix_test)\n",
    "h11_model_test_score       = Score(y_true=h11_test, y_pred=h11_model_test_predictions, rounding=np.rint)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(h11_model_test_score.accuracy()*100))\n",
    "\n",
    "log.info('Fitting the model for h21...')\n",
    "h21_model, h21_model_history = cnn_fit(network_h21,\n",
    "                                       matrix_train_lv1,\n",
    "                                       h21_matrix_train_lv1,\n",
    "                                       matrix_val_lv1,\n",
    "                                       h21_matrix_val_lv1,\n",
    "                                       batch_size=32,\n",
    "                                       epochs=100,\n",
    "                                       early_stopping=10,\n",
    "                                       reduce_lr=5,\n",
    "                                       verbose=0\n",
    "                                      )\n",
    "h21_model_predictions      = h21_model.predict(matrix_train_lv2)\n",
    "h21_model_test_predictions = h21_model.predict(matrix_test)\n",
    "h21_model_test_score       = Score(y_true=h21_test, y_pred=h21_model_test_predictions, rounding=np.rint)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(h21_model_test_score.accuracy()*100))\n",
    "\n",
    "plot = Plot(rows=1, columns=1)\n",
    "\n",
    "plot.hist2D(h11_model_test_score.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(h11_model_test_score.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'neural_network_lv1_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'neural_network_lv1_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Level Training\n",
    "\n",
    "We then stack the predictions we obtained from the first level training and train a **meta estimator** on the newly produced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack second level predictions\n",
    "h11_new_feat = np.c_[el_net_preds_h11, svr_rbf_preds_h11, rnd_for_preds_h11, h11_model_predictions]\n",
    "h21_new_feat = np.c_[el_net_preds_h21, svr_rbf_preds_h21, rnd_for_preds_h21, h21_model_predictions]\n",
    "\n",
    "# stack test predictions\n",
    "h11_new_test_feat = np.c_[el_net_test_preds_h11, svr_rbf_test_preds_h11, rnd_for_test_preds_h11, h11_model_test_predictions]\n",
    "h21_new_test_feat = np.c_[el_net_test_preds_h21, svr_rbf_test_preds_h21, rnd_for_test_preds_h21, h21_model_test_predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "\n",
    "We then use a **L1** regularized version of linear regression as a **meta** learner. In this case we will control a slightly higher number of hyperparameters:\n",
    "\n",
    "- `fit_intercept` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `normalize` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `alpha` $\\in \\left[ 10^{-6}, 10^{-1} \\right]$,\n",
    "- `positive` $\\in \\lbrace 0, 1 \\rbrace$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from skopt                import BayesSearchCV\n",
    "from skopt.space          import Integer, Real, Categorical\n",
    "from sklearn.metrics      import make_scorer\n",
    "from mltools.libscore     import accuracy, Score, ViewCV\n",
    "from mltools.libplot      import Plot\n",
    "\n",
    "log.info('Trainining lasso (as meta learner)...')\n",
    "\n",
    "rounding      = np.rint #---------------------------------------------------------- choose a rounding function\n",
    "n_iter        = 50 #--------------------------------------------------------------- the number of iteration of the Bayes search\n",
    "search_params = {'fit_intercept': Integer(0, 1),\n",
    "                 'normalize':     Integer(0, 1),\n",
    "                 'positive':      Integer(0, 1),\n",
    "                 'alpha':         Real(1.0e-6, 1.0e-1, prior='log-uniform')\n",
    "                } #---------------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(Lasso(random_state=RAND, max_iter=1e5), #------------ choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #------------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "estimator.fit(h11_new_feat, h11_train_lv2) #----------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "svr_rbf_test_preds_h11   = estimator.best_estimator_.predict(h11_new_test_feat) #---------------- compute predictions for h11 (test)\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=svr_rbf_test_preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(h21_new_feat, h21_train_lv2) #----------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "svr_rbf_test_preds_h21   = estimator.best_estimator_.predict(h21_new_test_feat) #---------------- compute predictions for h21 (test)\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=svr_rbf_test_preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=1) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lasso_lv2_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lasso_lv2_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Conclusions\n",
    "\n",
    "Even though the algorithms are quite diverse in nature, they tend to have overlapping regions of _good performance_ (they all perform best in the central region of `num_cp`, for example) and the stacked ensemble cannot really exploit their differences to improve the results. Instead it starts to suffer from not having the entire set for training (also in the reference paper they mention a drop in accuracy when taking less samples in the training set).\n",
    "\n",
    "We do not think that adding the neural networks to the stack would actually benefit: neural networks seem to outperform by a long shot both decision trees and support vector machines. The latters would only contribute in worsening the results of the _convolutional networks_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
