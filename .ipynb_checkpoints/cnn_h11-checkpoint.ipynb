{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "We study the performance of CNN architectures on the configuration matrices of CICY 3-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# set memory growth (necessary for training)\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Dataset\n",
    "\n",
    "We first download and unzip the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, tarfile, os\n",
    "\n",
    "file_url = 'http://www.lpthe.jussieu.fr/~erbin/files/data/cicy3o_data.tar.gz'\n",
    "file_out = './cicy3o.tar.gz'\n",
    "file_dat = 'cicy3o.h5'\n",
    "\n",
    "if not os.path.isfile(file_out):\n",
    "    urllib.request.urlretrieve(file_url, file_out)\n",
    "    \n",
    "if not os.path.isfile(file_dat):\n",
    "    with tarfile.open(file_out, 'r') as tar:\n",
    "        tar.extract(file_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "We then load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dat = pd.read_hdf(os.path.join('.', file_dat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the outliers (keep $h^{1,1} \\in [1, 16]$ and $h^{2,1} \\in [15, 86]$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_out   = dat\n",
    "dat_noout = dat.loc[(dat['h11'] > 0) &\n",
    "                    (dat['h11'] < 17) &\n",
    "                    (dat['h21'] > 14) &\n",
    "                    (dat['h21'] < 87)\n",
    "                   ]\n",
    "\n",
    "dat_out   = dat_out[['h11', 'matrix']]\n",
    "dat_noout = dat_noout[['h11', 'matrix']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then extract the `matrix` column into its dense format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_series(series: pd.Series) -> pd.Series:\n",
    "    '''\n",
    "    Extract a Pandas series into its dense format.\n",
    "    \n",
    "    Required arguments:\n",
    "        series: the pandas series.\n",
    "        \n",
    "    Returns:\n",
    "        the pandas series in dense format.\n",
    "    '''\n",
    "    # avoid direct overwriting\n",
    "    series = series.copy()\n",
    "    \n",
    "    # cget the maximum size of each axis\n",
    "    max_shape = series.apply(np.shape).max()\n",
    "    \n",
    "    # return the transformed series\n",
    "    if np.prod(max_shape) > 1:\n",
    "        # compute the necessary shift and apply it\n",
    "        offset = lambda s: [(0, max_shape[i] - np.shape(s)[i])\n",
    "                            for i in range(len(max_shape))\n",
    "                           ]\n",
    "        return series.apply(lambda s: np.pad(s, offset(s), mode='constant'))\n",
    "    else:\n",
    "        return series\n",
    "    \n",
    "# apply it to the matrix\n",
    "dat_out   = dat_out.apply(extract_series)\n",
    "dat_noout = dat_noout.apply(extract_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Strategy\n",
    "\n",
    "We then subsample the set into training, validation and test sets for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training data:\n",
      "    Training set w/ outliers:   80.00%\n",
      "    Validation set w/ outliers: 10.00%\n",
      "    Test set w/ outliers:       10.00%\n",
      "\n",
      "    Training set w/o outliers:   79.99%\n",
      "    Validation set w/o outliers: 10.00%\n",
      "    Test set w/o outliers:       10.01%\n",
      "\n",
      "30% training data:\n",
      "    Training set w/ outliers:   30.00%\n",
      "    Validation set w/ outliers: 10.00%\n",
      "    Test set w/ outliers:       60.00%\n",
      "\n",
      "    Training set w/o outliers:   30.00%\n",
      "    Validation set w/o outliers: 10.00%\n",
      "    Test set w/o outliers:       60.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set random state\n",
    "RAND = 42\n",
    "np.random.seed(RAND)\n",
    "tf.random.set_seed(RAND)\n",
    "\n",
    "# split training set\n",
    "dat_out_train_80,   dat_out_test_80   = train_test_split(dat_out, train_size=0.8, shuffle=True, random_state=RAND)\n",
    "dat_out_train_30,   dat_out_test_30   = train_test_split(dat_out, train_size=0.3, shuffle=True, random_state=RAND)\n",
    "dat_noout_train_80, dat_noout_test_80 = train_test_split(dat_noout, train_size=0.8, shuffle=True, random_state=RAND)\n",
    "dat_noout_train_30, dat_noout_test_30 = train_test_split(dat_noout, train_size=0.3, shuffle=True, random_state=RAND)\n",
    "\n",
    "# split validation set\n",
    "dat_out_val_80,   dat_out_test_80   = train_test_split(dat_out_test_80, train_size=0.5, shuffle=True, random_state=RAND)\n",
    "dat_out_val_30,   dat_out_test_30   = train_test_split(dat_out_test_30, train_size=1/7, shuffle=True, random_state=RAND)\n",
    "dat_noout_val_80, dat_noout_test_80 = train_test_split(dat_noout_test_80, train_size=0.5, shuffle=True, random_state=RAND)\n",
    "dat_noout_val_30, dat_noout_test_30 = train_test_split(dat_noout_test_30, train_size=1/7, shuffle=True, random_state=RAND)\n",
    "\n",
    "# check sizes\n",
    "print('80% training data:')\n",
    "print('    Training set w/ outliers:   {:.2f}%'.format(100 * dat_out_train_80.shape[0] / dat_out.shape[0]))\n",
    "print('    Validation set w/ outliers: {:.2f}%'.format(100 * dat_out_val_80.shape[0] / dat_out.shape[0]))\n",
    "print('    Test set w/ outliers:       {:.2f}%'.format(100 * dat_out_test_80.shape[0] / dat_out.shape[0]))\n",
    "print('')\n",
    "print('    Training set w/o outliers:   {:.2f}%'.format(100 * dat_noout_train_80.shape[0] / dat_noout.shape[0]))\n",
    "print('    Validation set w/o outliers: {:.2f}%'.format(100 * dat_noout_val_80.shape[0] / dat_noout.shape[0]))\n",
    "print('    Test set w/o outliers:       {:.2f}%'.format(100 * dat_noout_test_80.shape[0] / dat_noout.shape[0]))\n",
    "print('')\n",
    "print('30% training data:')\n",
    "print('    Training set w/ outliers:   {:.2f}%'.format(100 * dat_out_train_30.shape[0] / dat_out.shape[0]))\n",
    "print('    Validation set w/ outliers: {:.2f}%'.format(100 * dat_out_val_30.shape[0] / dat_out.shape[0]))\n",
    "print('    Test set w/ outliers:       {:.2f}%'.format(100 * dat_out_test_30.shape[0] / dat_out.shape[0]))\n",
    "print('')\n",
    "print('    Training set w/o outliers:   {:.2f}%'.format(100 * dat_noout_train_30.shape[0] / dat_noout.shape[0]))\n",
    "print('    Validation set w/o outliers: {:.2f}%'.format(100 * dat_noout_val_30.shape[0] / dat_noout.shape[0]))\n",
    "print('    Test set w/o outliers:       {:.2f}%'.format(100 * dat_noout_test_30.shape[0] / dat_noout.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Visualisation (Training Set)\n",
    "\n",
    "We then want to visualise the input matrices for comparison with the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('img', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Samples\n",
    "\n",
    "We first visualise random samples in the training set (they must be scaled in the interval $[0,1]$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1440 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "# normalisation factor (use the matrix w/o outliers to avoid getting an outlier)\n",
    "max_train_entry = dat_noout_train_80['matrix'].apply(np.max).max()\n",
    "\n",
    "ncols = 4\n",
    "nrows = 4\n",
    "_, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols, 5 * nrows))\n",
    "\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        \n",
    "        matrix = dat_noout_train_80['matrix'].\\\n",
    "                    iloc[np.random.randint(low=0,\n",
    "                                           high=dat_noout_train_80.shape[0] - 1\n",
    "                                          )\n",
    "                        ]\n",
    "        sns.heatmap(data=matrix / max_train_entry,\n",
    "                    vmin=0.0,\n",
    "                    vmax=1.0,\n",
    "                    ax=ax[i,j],\n",
    "                    cmap='Blues',\n",
    "                    xticklabels=False,\n",
    "                    yticklabels=False\n",
    "                   )\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('./img/train_samples_rnd.pdf', dpi=150, format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Entries\n",
    "\n",
    "We then compute the average of all entries as a representative of the training set (first of all we scale the input and then take the mean value of each entry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_mat = dat_noout_train_80['matrix'] / max_train_entry\n",
    "avg_mat = avg_mat.mean()\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "sns.heatmap(data=avg_mat,\n",
    "            vmin=0.0,\n",
    "            vmax=1.0,\n",
    "            ax=ax,\n",
    "            cmap='Blues',\n",
    "            xticklabels=False,\n",
    "            yticklabels=False\n",
    "           )\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('./img/train_samples_avg.pdf', dpi=150, format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architectures\n",
    "\n",
    "We then study both a sequential CNN and the Inception-like CNN to analyse their feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix\n",
    "mat_out_train_80   = np.array(dat_out_train_80['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "mat_noout_train_80 = np.array(dat_noout_train_80['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "mat_out_train_30   = np.array(dat_out_train_30['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "mat_noout_train_30 = np.array(dat_noout_train_30['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "\n",
    "mat_out_val_80     = np.array(dat_out_val_80['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "mat_noout_val_80   = np.array(dat_noout_val_80['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "mat_out_val_30     = np.array(dat_out_val_30['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "mat_noout_val_30   = np.array(dat_noout_val_30['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "\n",
    "mat_out_test_80    = np.array(dat_out_test_80['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "mat_noout_test_80  = np.array(dat_noout_test_80['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "mat_out_test_30    = np.array(dat_out_test_30['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "mat_noout_test_30  = np.array(dat_noout_test_30['matrix'].tolist()).reshape(-1, 12, 15, 1)\n",
    "\n",
    "input_shape = (12, 15, 1)\n",
    "\n",
    "# labels\n",
    "lab_out_train_80 = dat_out_train_80['h11'].values.reshape(-1,1)\n",
    "lab_noout_train_80 = dat_noout_train_80['h11'].values.reshape(-1,1)\n",
    "lab_out_train_30 = dat_out_train_30['h11'].values.reshape(-1,1)\n",
    "lab_noout_train_30 = dat_noout_train_30['h11'].values.reshape(-1,1)\n",
    "\n",
    "lab_out_val_80   = dat_out_val_80['h11'].values.reshape(-1,1)\n",
    "lab_noout_val_80   = dat_noout_val_80['h11'].values.reshape(-1,1)\n",
    "lab_out_val_30   = dat_out_val_30['h11'].values.reshape(-1,1)\n",
    "lab_noout_val_30   = dat_noout_val_30['h11'].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "lab_out_test_80   = dat_out_test_80['h11'].values.reshape(-1,1)\n",
    "lab_noout_test_80   = dat_noout_test_80['h11'].values.reshape(-1,1)\n",
    "lab_out_test_30   = dat_out_test_30['h11'].values.reshape(-1,1)\n",
    "lab_noout_test_30   = dat_noout_test_30['h11'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdir\n",
    "os.makedirs('./mod', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def inc_model(input_shape,\n",
    "              model_name='inception',\n",
    "              learning_rate=0.001,\n",
    "              filters=[32],\n",
    "              kernel_size=[(3,3), (5,5)],\n",
    "              dropout=0.2,\n",
    "              momentum=0.99,\n",
    "              l1_reg=0.0,\n",
    "              l2_reg=0.0\n",
    "             ):\n",
    "    \n",
    "    # reset session\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # define the regularisation factor\n",
    "    kernel_regularizer = keras.regularizers.l1_l2(l1=l1_reg, l2=l2_reg)\n",
    "    \n",
    "    # input of the model\n",
    "    I = keras.layers.Input(shape=input_shape, name=model_name + '_input')\n",
    "    x = I\n",
    "    \n",
    "    # convolutional layers\n",
    "    for n in range(len(filters)):\n",
    "        a = keras.layers.Conv2D(filters=filters[n],\n",
    "                                kernel_size=kernel_size[0],\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=kernel_regularizer,\n",
    "                                activation='relu',\n",
    "                                name=model_name + '_convA_' + str(n+1)\n",
    "                               )(x)\n",
    "        b = keras.layers.Conv2D(filters=filters[n],\n",
    "                                kernel_size=kernel_size[1],\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=kernel_regularizer,\n",
    "                                activation='relu',\n",
    "                                name=model_name + '_convB_' + str(n+1)\n",
    "                               )(x)\n",
    "        x = keras.layers.concatenate([a, b], name=model_name + '_conc_' + str(n+1))\n",
    "        if momentum > 0.0:\n",
    "            x = keras.layers.BatchNormalization(momentum=momentum,\n",
    "                                                name=model_name + '_bnorm_' + str(n+1)\n",
    "                                               )(x)\n",
    "    \n",
    "    # dropout layer\n",
    "    if dropout > 0.0:\n",
    "        x = keras.layers.Dropout(rate=dropout, name=model_name + '_drop')(x)\n",
    "        \n",
    "    # flatten\n",
    "    x = keras.layers.Flatten(name=model_name + '_flat')(x)\n",
    "    \n",
    "    # output\n",
    "    h11 = keras.layers.Dense(units=1,\n",
    "                             activation='relu',\n",
    "                             name='h11_output'\n",
    "                            )(x)\n",
    "    \n",
    "    # define the model\n",
    "    model = keras.models.Model(inputs=I, outputs=h11, name=model_name)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='mse',\n",
    "                  metrics=['mse', 'mae']\n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_line = inc_model(input_shape=input_shape,\n",
    "                           model_name='inc_line',\n",
    "                           learning_rate=0.001,\n",
    "                           filters=[32, 64, 32],\n",
    "                           kernel_size=[(12,1), (1,15)],\n",
    "                           dropout=0.2,\n",
    "                           l1_reg=1.0e-4,\n",
    "                           l2_reg=1.0e-4\n",
    "                          )\n",
    "inception_square = inc_model(input_shape=input_shape,\n",
    "                             model_name='inc_square',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[32, 64, 32],\n",
    "                             kernel_size=[(3,3), (5,5)],\n",
    "                             dropout=0.2,\n",
    "                             l1_reg=1.0e-4,\n",
    "                             l2_reg=1.0e-4\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be visualised using `keras` utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image\n",
    "\n",
    "inception_line_dot = keras.utils.model_to_dot(inception_line,\n",
    "                                              show_shapes=True,\n",
    "                                              dpi=150\n",
    "                                             )\n",
    "inception_line_dot.write_pdf('./img/inc_arch_h11.pdf')\n",
    "#Image(inception_line_dot.create_png(), width=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./dat', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80% Training Data w/ Outliers (line kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 80% data w/ outliers (line kernel)\n",
      "Model: \"inc_line\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inc_line_input (InputLayer)     [(None, 12, 15, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_1 (Conv2D)       (None, 12, 15, 32)   416         inc_line_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_1 (Conv2D)       (None, 12, 15, 32)   512         inc_line_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_1 (Concatenate)   (None, 12, 15, 64)   0           inc_line_convA_1[0][0]           \n",
      "                                                                 inc_line_convB_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_1 (BatchNormaliz (None, 12, 15, 64)   256         inc_line_conc_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_2 (Conv2D)       (None, 12, 15, 64)   49216       inc_line_bnorm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_2 (Conv2D)       (None, 12, 15, 64)   61504       inc_line_bnorm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_2 (Concatenate)   (None, 12, 15, 128)  0           inc_line_convA_2[0][0]           \n",
      "                                                                 inc_line_convB_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_2 (BatchNormaliz (None, 12, 15, 128)  512         inc_line_conc_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_3 (Conv2D)       (None, 12, 15, 32)   49184       inc_line_bnorm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_3 (Conv2D)       (None, 12, 15, 32)   61472       inc_line_bnorm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_3 (Concatenate)   (None, 12, 15, 64)   0           inc_line_convA_3[0][0]           \n",
      "                                                                 inc_line_convB_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_3 (BatchNormaliz (None, 12, 15, 64)   256         inc_line_conc_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_drop (Dropout)         (None, 12, 15, 64)   0           inc_line_bnorm_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_flat (Flatten)         (None, 11520)        0           inc_line_drop[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "h11_output (Dense)              (None, 1)            11521       inc_line_flat[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 234,849\n",
      "Trainable params: 234,337\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/inception_line_out_80_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "print('Training 80% data w/ outliers (line kernel)')\n",
    "inception_line.summary()\n",
    "\n",
    "# define the model\n",
    "inception_line = inc_model(input_shape=input_shape,\n",
    "                           model_name='inc_line',\n",
    "                           learning_rate=0.001,\n",
    "                           filters=[32, 64, 32],\n",
    "                           kernel_size=[(12,1), (1,15)],\n",
    "                           dropout=0.2,\n",
    "                           l1_reg=1.0e-4,\n",
    "                           l2_reg=1.0e-4\n",
    "                          )\n",
    "inc_line_out_80 = inception_line.fit(x=mat_out_train_80,\n",
    "                                     y=lab_out_train_80,\n",
    "                                     batch_size=32,\n",
    "                                     epochs=10,\n",
    "                                     verbose=0,\n",
    "                                     callbacks=callbacks,\n",
    "                                     validation_data=(mat_out_val_80, lab_out_val_80)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 55.13%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(inception_line.predict(mat_out_test_80)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_out_test_80.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true,\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/inc_line_out_80_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(inc_line_out_80.history, './dat/inc_line_out_80_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80% Training Data w/o Outliers (line kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inc_line\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inc_line_input (InputLayer)     [(None, 12, 15, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_1 (Conv2D)       (None, 12, 15, 32)   416         inc_line_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_1 (Conv2D)       (None, 12, 15, 32)   512         inc_line_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_1 (Concatenate)   (None, 12, 15, 64)   0           inc_line_convA_1[0][0]           \n",
      "                                                                 inc_line_convB_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_1 (BatchNormaliz (None, 12, 15, 64)   256         inc_line_conc_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_2 (Conv2D)       (None, 12, 15, 64)   49216       inc_line_bnorm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_2 (Conv2D)       (None, 12, 15, 64)   61504       inc_line_bnorm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_2 (Concatenate)   (None, 12, 15, 128)  0           inc_line_convA_2[0][0]           \n",
      "                                                                 inc_line_convB_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_2 (BatchNormaliz (None, 12, 15, 128)  512         inc_line_conc_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_3 (Conv2D)       (None, 12, 15, 32)   49184       inc_line_bnorm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_3 (Conv2D)       (None, 12, 15, 32)   61472       inc_line_bnorm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_3 (Concatenate)   (None, 12, 15, 64)   0           inc_line_convA_3[0][0]           \n",
      "                                                                 inc_line_convB_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_3 (BatchNormaliz (None, 12, 15, 64)   256         inc_line_conc_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_drop (Dropout)         (None, 12, 15, 64)   0           inc_line_bnorm_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_flat (Flatten)         (None, 11520)        0           inc_line_drop[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "h11_output (Dense)              (None, 1)            11521       inc_line_flat[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 234,849\n",
      "Trainable params: 234,337\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "Training 80% data w/o outliers (line kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/inception_line_noout_80_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "inception_line.summary()\n",
    "\n",
    "print('Training 80% data w/o outliers (line kernel)')\n",
    "\n",
    "# define the model\n",
    "inception_line = inc_model(input_shape=input_shape,\n",
    "                           model_name='inc_line',\n",
    "                           learning_rate=0.001,\n",
    "                           filters=[32, 64, 32],\n",
    "                           kernel_size=[(12,1), (1,15)],\n",
    "                           dropout=0.2,\n",
    "                           l1_reg=1.0e-4,\n",
    "                           l2_reg=1.0e-4\n",
    "                          )\n",
    "inc_line_noout_80 = inception_line.fit(x=mat_noout_train_80,\n",
    "                                       y=lab_noout_train_80,\n",
    "                                       batch_size=32,\n",
    "                                       epochs=10,\n",
    "                                       verbose=0,\n",
    "                                       callbacks=callbacks,\n",
    "                                       validation_data=(mat_noout_val_80, lab_noout_val_80)\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 9.29%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(inception_line.predict(mat_noout_test_80)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_noout_test_80.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/inc_line_noout_80_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(inc_line_noout_80.history, './dat/inc_line_noout_80_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30% Training Data w/ Outliers (line kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inc_line\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inc_line_input (InputLayer)     [(None, 12, 15, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_1 (Conv2D)       (None, 12, 15, 32)   416         inc_line_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_1 (Conv2D)       (None, 12, 15, 32)   512         inc_line_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_1 (Concatenate)   (None, 12, 15, 64)   0           inc_line_convA_1[0][0]           \n",
      "                                                                 inc_line_convB_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_1 (BatchNormaliz (None, 12, 15, 64)   256         inc_line_conc_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_2 (Conv2D)       (None, 12, 15, 64)   49216       inc_line_bnorm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_2 (Conv2D)       (None, 12, 15, 64)   61504       inc_line_bnorm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_2 (Concatenate)   (None, 12, 15, 128)  0           inc_line_convA_2[0][0]           \n",
      "                                                                 inc_line_convB_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_2 (BatchNormaliz (None, 12, 15, 128)  512         inc_line_conc_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_3 (Conv2D)       (None, 12, 15, 32)   49184       inc_line_bnorm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_3 (Conv2D)       (None, 12, 15, 32)   61472       inc_line_bnorm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_3 (Concatenate)   (None, 12, 15, 64)   0           inc_line_convA_3[0][0]           \n",
      "                                                                 inc_line_convB_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_3 (BatchNormaliz (None, 12, 15, 64)   256         inc_line_conc_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_drop (Dropout)         (None, 12, 15, 64)   0           inc_line_bnorm_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_flat (Flatten)         (None, 11520)        0           inc_line_drop[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "h11_output (Dense)              (None, 1)            11521       inc_line_flat[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 234,849\n",
      "Trainable params: 234,337\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "Training 30% data w/ outliers (line kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/inception_line_out_30_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "inception_line.summary()\n",
    "\n",
    "print('Training 30% data w/ outliers (line kernel)')\n",
    "\n",
    "# define the model\n",
    "inception_line = inc_model(input_shape=input_shape,\n",
    "                           model_name='inc_line',\n",
    "                           learning_rate=0.001,\n",
    "                           filters=[32, 64, 32],\n",
    "                           kernel_size=[(12,1), (1,15)],\n",
    "                           dropout=0.2,\n",
    "                           l1_reg=1.0e-4,\n",
    "                           l2_reg=1.0e-4\n",
    "                          )\n",
    "inc_line_out_30 = inception_line.fit(x=mat_out_train_30,\n",
    "                                     y=lab_out_train_30,\n",
    "                                     batch_size=32,\n",
    "                                     epochs=10,\n",
    "                                     verbose=0,\n",
    "                                     callbacks=callbacks,\n",
    "                                     validation_data=(mat_out_val_30, lab_out_val_30)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 9.80%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(inception_line.predict(mat_out_test_30)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_out_test_30.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/inc_line_out_30_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(inc_line_out_30.history, './dat/inc_line_out_30_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30% Training Data w/o Outliers (line kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inc_line\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inc_line_input (InputLayer)     [(None, 12, 15, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_1 (Conv2D)       (None, 12, 15, 32)   416         inc_line_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_1 (Conv2D)       (None, 12, 15, 32)   512         inc_line_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_1 (Concatenate)   (None, 12, 15, 64)   0           inc_line_convA_1[0][0]           \n",
      "                                                                 inc_line_convB_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_1 (BatchNormaliz (None, 12, 15, 64)   256         inc_line_conc_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_2 (Conv2D)       (None, 12, 15, 64)   49216       inc_line_bnorm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_2 (Conv2D)       (None, 12, 15, 64)   61504       inc_line_bnorm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_2 (Concatenate)   (None, 12, 15, 128)  0           inc_line_convA_2[0][0]           \n",
      "                                                                 inc_line_convB_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_2 (BatchNormaliz (None, 12, 15, 128)  512         inc_line_conc_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convA_3 (Conv2D)       (None, 12, 15, 32)   49184       inc_line_bnorm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_convB_3 (Conv2D)       (None, 12, 15, 32)   61472       inc_line_bnorm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_conc_3 (Concatenate)   (None, 12, 15, 64)   0           inc_line_convA_3[0][0]           \n",
      "                                                                 inc_line_convB_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_bnorm_3 (BatchNormaliz (None, 12, 15, 64)   256         inc_line_conc_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_drop (Dropout)         (None, 12, 15, 64)   0           inc_line_bnorm_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_line_flat (Flatten)         (None, 11520)        0           inc_line_drop[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "h11_output (Dense)              (None, 1)            11521       inc_line_flat[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 234,849\n",
      "Trainable params: 234,337\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "Training 30% data w/o outliers (line kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/inception_line_noout_30_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "inception_line.summary()\n",
    "\n",
    "print('Training 30% data w/o outliers (line kernel)')\n",
    "\n",
    "# define the model\n",
    "inception_line = inc_model(input_shape=input_shape,\n",
    "                           model_name='inc_line',\n",
    "                           learning_rate=0.001,\n",
    "                           filters=[32, 64, 32],\n",
    "                           kernel_size=[(12,1), (1,15)],\n",
    "                           dropout=0.2,\n",
    "                           l1_reg=1.0e-4,\n",
    "                           l2_reg=1.0e-4\n",
    "                          )\n",
    "inc_line_noout_30 = inception_line.fit(x=mat_noout_train_30,\n",
    "                                       y=lab_noout_train_30,\n",
    "                                       batch_size=32,\n",
    "                                       epochs=10,\n",
    "                                       verbose=0,\n",
    "                                       callbacks=callbacks,\n",
    "                                       validation_data=(mat_noout_val_30, lab_noout_val_30)\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 4.88%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(inception_line.predict(mat_noout_test_30)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_noout_test_30.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/inc_line_noout_30_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(inc_line_noout_30.history, './dat/inc_line_noout_30_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80% Training Data w/ Outliers (square kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inc_square\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inc_square_input (InputLayer)   [(None, 12, 15, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_1 (Conv2D)     (None, 12, 15, 64)   640         inc_square_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_1 (Conv2D)     (None, 12, 15, 64)   1664        inc_square_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_1 (Concatenate) (None, 12, 15, 128)  0           inc_square_convA_1[0][0]         \n",
      "                                                                 inc_square_convB_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_1 (BatchNormal (None, 12, 15, 128)  512         inc_square_conc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_2 (Conv2D)     (None, 12, 15, 64)   73792       inc_square_bnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_2 (Conv2D)     (None, 12, 15, 64)   204864      inc_square_bnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_2 (Concatenate) (None, 12, 15, 128)  0           inc_square_convA_2[0][0]         \n",
      "                                                                 inc_square_convB_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_2 (BatchNormal (None, 12, 15, 128)  512         inc_square_conc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_3 (Conv2D)     (None, 12, 15, 32)   36896       inc_square_bnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_3 (Conv2D)     (None, 12, 15, 32)   102432      inc_square_bnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_3 (Concatenate) (None, 12, 15, 64)   0           inc_square_convA_3[0][0]         \n",
      "                                                                 inc_square_convB_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_3 (BatchNormal (None, 12, 15, 64)   256         inc_square_conc_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_drop (Dropout)       (None, 12, 15, 64)   0           inc_square_bnorm_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_flat (Flatten)       (None, 11520)        0           inc_square_drop[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "h11_output (Dense)              (None, 1)            11521       inc_square_flat[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 433,089\n",
      "Trainable params: 432,449\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n",
      "Training 80% data w/ outliers (square kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/inception_square_out_80_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "inception_square.summary()\n",
    "\n",
    "print('Training 80% data w/ outliers (square kernel)')\n",
    "\n",
    "# define the model\n",
    "inception_square = inc_model(input_shape=input_shape,\n",
    "                             model_name='inc_square',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[32, 64, 32],\n",
    "                             kernel_size=[(3,3), (5,5)],\n",
    "                             dropout=0.2,\n",
    "                             l1_reg=1.0e-4,\n",
    "                             l2_reg=1.0e-4\n",
    "                            )\n",
    "inc_square_out_80 = inception_square.fit(x=mat_out_train_80,\n",
    "                                         y=lab_out_train_80,\n",
    "                                         batch_size=32,\n",
    "                                         epochs=10,\n",
    "                                         verbose=0,\n",
    "                                         callbacks=callbacks,\n",
    "                                         validation_data=(mat_out_val_80, lab_out_val_80)\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 82.89%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(inception_square.predict(mat_out_test_80)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_out_test_80.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/inc_square_out_80_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(inc_square_out_80.history, './dat/inc_square_out_80_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80% Training Data w/o Outliers (square kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inc_square\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inc_square_input (InputLayer)   [(None, 12, 15, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_1 (Conv2D)     (None, 12, 15, 32)   320         inc_square_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_1 (Conv2D)     (None, 12, 15, 32)   832         inc_square_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_1 (Concatenate) (None, 12, 15, 64)   0           inc_square_convA_1[0][0]         \n",
      "                                                                 inc_square_convB_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_1 (BatchNormal (None, 12, 15, 64)   256         inc_square_conc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_2 (Conv2D)     (None, 12, 15, 64)   36928       inc_square_bnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_2 (Conv2D)     (None, 12, 15, 64)   102464      inc_square_bnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_2 (Concatenate) (None, 12, 15, 128)  0           inc_square_convA_2[0][0]         \n",
      "                                                                 inc_square_convB_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_2 (BatchNormal (None, 12, 15, 128)  512         inc_square_conc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_3 (Conv2D)     (None, 12, 15, 32)   36896       inc_square_bnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_3 (Conv2D)     (None, 12, 15, 32)   102432      inc_square_bnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_3 (Concatenate) (None, 12, 15, 64)   0           inc_square_convA_3[0][0]         \n",
      "                                                                 inc_square_convB_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_3 (BatchNormal (None, 12, 15, 64)   256         inc_square_conc_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_drop (Dropout)       (None, 12, 15, 64)   0           inc_square_bnorm_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_flat (Flatten)       (None, 11520)        0           inc_square_drop[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "h11_output (Dense)              (None, 1)            11521       inc_square_flat[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 292,417\n",
      "Trainable params: 291,905\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "Training 80% data w/o outliers (square kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/inception_square_noout_80_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "inception_square.summary()\n",
    "\n",
    "print('Training 80% data w/o outliers (square kernel)')\n",
    "\n",
    "# define the model\n",
    "inception_square = inc_model(input_shape=input_shape,\n",
    "                             model_name='inc_square',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[32, 64, 32],\n",
    "                             kernel_size=[(3,3), (5,5)],\n",
    "                             dropout=0.2,\n",
    "                             l1_reg=1.0e-4,\n",
    "                             l2_reg=1.0e-4\n",
    "                            )\n",
    "inc_square_noout_80 = inception_square.fit(x=mat_noout_train_80,\n",
    "                                           y=lab_noout_train_80,\n",
    "                                           batch_size=32,\n",
    "                                           epochs=10,\n",
    "                                           verbose=0,\n",
    "                                           callbacks=callbacks,\n",
    "                                           validation_data=(mat_noout_val_80, lab_noout_val_80)\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 88.93%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(inception_square.predict(mat_noout_test_80)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_noout_test_80.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/inc_square_noout_80_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(inc_square_noout_80.history, './dat/inc_square_noout_80_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30% Training Data w/ Outliers (square kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inc_square\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inc_square_input (InputLayer)   [(None, 12, 15, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_1 (Conv2D)     (None, 12, 15, 32)   416         inc_square_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_1 (Conv2D)     (None, 12, 15, 32)   512         inc_square_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_1 (Concatenate) (None, 12, 15, 64)   0           inc_square_convA_1[0][0]         \n",
      "                                                                 inc_square_convB_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_1 (BatchNormal (None, 12, 15, 64)   256         inc_square_conc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_2 (Conv2D)     (None, 12, 15, 64)   49216       inc_square_bnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_2 (Conv2D)     (None, 12, 15, 64)   61504       inc_square_bnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_2 (Concatenate) (None, 12, 15, 128)  0           inc_square_convA_2[0][0]         \n",
      "                                                                 inc_square_convB_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_2 (BatchNormal (None, 12, 15, 128)  512         inc_square_conc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_3 (Conv2D)     (None, 12, 15, 32)   49184       inc_square_bnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_3 (Conv2D)     (None, 12, 15, 32)   61472       inc_square_bnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_3 (Concatenate) (None, 12, 15, 64)   0           inc_square_convA_3[0][0]         \n",
      "                                                                 inc_square_convB_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_3 (BatchNormal (None, 12, 15, 64)   256         inc_square_conc_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_drop (Dropout)       (None, 12, 15, 64)   0           inc_square_bnorm_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_flat (Flatten)       (None, 11520)        0           inc_square_drop[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "h11_output (Dense)              (None, 1)            11521       inc_square_flat[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 234,849\n",
      "Trainable params: 234,337\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "Training 30% data w/ outliers (square kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/inception_square_out_30_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "inception_square.summary()\n",
    "\n",
    "print('Training 30% data w/ outliers (square kernel)')\n",
    "\n",
    "# define the model\n",
    "inception_square = inc_model(input_shape=input_shape,\n",
    "                             model_name='inc_square',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[32, 64, 32],\n",
    "                             kernel_size=[(3,3), (5,5)],\n",
    "                             dropout=0.2,\n",
    "                             l1_reg=1.0e-4,\n",
    "                             l2_reg=1.0e-4\n",
    "                            )\n",
    "inc_square_out_30 = inception_square.fit(x=mat_out_train_30,\n",
    "                                         y=lab_out_train_30,\n",
    "                                         batch_size=32,\n",
    "                                         epochs=10,\n",
    "                                         verbose=0,\n",
    "                                         callbacks=callbacks,\n",
    "                                         validation_data=(mat_out_val_30, lab_out_val_30)\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 19.16%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(inception_square.predict(mat_out_test_30)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_out_test_30.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/inc_square_out_30_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(inc_square_out_30.history, './dat/inc_square_out_30_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30% Training Data w/o Outliers (square kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inc_square\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inc_square_input (InputLayer)   [(None, 12, 15, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_1 (Conv2D)     (None, 12, 15, 32)   320         inc_square_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_1 (Conv2D)     (None, 12, 15, 32)   832         inc_square_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_1 (Concatenate) (None, 12, 15, 64)   0           inc_square_convA_1[0][0]         \n",
      "                                                                 inc_square_convB_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_1 (BatchNormal (None, 12, 15, 64)   256         inc_square_conc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_2 (Conv2D)     (None, 12, 15, 64)   36928       inc_square_bnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_2 (Conv2D)     (None, 12, 15, 64)   102464      inc_square_bnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_2 (Concatenate) (None, 12, 15, 128)  0           inc_square_convA_2[0][0]         \n",
      "                                                                 inc_square_convB_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_2 (BatchNormal (None, 12, 15, 128)  512         inc_square_conc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convA_3 (Conv2D)     (None, 12, 15, 32)   36896       inc_square_bnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_convB_3 (Conv2D)     (None, 12, 15, 32)   102432      inc_square_bnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_conc_3 (Concatenate) (None, 12, 15, 64)   0           inc_square_convA_3[0][0]         \n",
      "                                                                 inc_square_convB_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_bnorm_3 (BatchNormal (None, 12, 15, 64)   256         inc_square_conc_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_drop (Dropout)       (None, 12, 15, 64)   0           inc_square_bnorm_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inc_square_flat (Flatten)       (None, 11520)        0           inc_square_drop[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "h11_output (Dense)              (None, 1)            11521       inc_square_flat[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 292,417\n",
      "Trainable params: 291,905\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "Training 30% data w/o outliers (square kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/inception_square_noout_30_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "inception_square.summary()\n",
    "\n",
    "print('Training 30% data w/o outliers (square kernel)')\n",
    "\n",
    "# define the model\n",
    "inception_square = inc_model(input_shape=input_shape,\n",
    "                             model_name='inc_square',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[32, 64, 32],\n",
    "                             kernel_size=[(3,3), (5,5)],\n",
    "                             dropout=0.2,\n",
    "                             l1_reg=1.0e-4,\n",
    "                             l2_reg=1.0e-4\n",
    "                            )\n",
    "inc_square_noout_30 = inception_square.fit(x=mat_noout_train_30,\n",
    "                                           y=lab_noout_train_30,\n",
    "                                           batch_size=32,\n",
    "                                           epochs=10,\n",
    "                                           verbose=0,\n",
    "                                           callbacks=callbacks,\n",
    "                                           validation_data=(mat_noout_val_30, lab_noout_val_30)\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 1.80%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(inception_square.predict(mat_noout_test_30)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_noout_test_30.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/inc_square_noout_30_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(inc_square_noout_30.history, './dat/inc_square_noout_30_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def seq_model(input_shape,\n",
    "              model_name='sequential',\n",
    "              learning_rate=0.001,\n",
    "              filters=[32],\n",
    "              padding='same',\n",
    "              kernel_size=(2,2),\n",
    "              dropout=0.2,\n",
    "              momentum=0.99,\n",
    "              l1_reg=0.0,\n",
    "              l2_reg=0.0\n",
    "             ):\n",
    "    \n",
    "    # reset session\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # define the regularisation factor\n",
    "    kernel_regularizer = keras.regularizers.l1_l2(l1=l1_reg, l2=l2_reg)\n",
    "    \n",
    "    # input of the model\n",
    "    I = keras.layers.Input(shape=input_shape, name=model_name + '_input')\n",
    "    x = I\n",
    "    \n",
    "    # convolutional layers\n",
    "    for n in range(len(filters)):\n",
    "        x = keras.layers.Conv2D(filters=filters[n],\n",
    "                                kernel_size=kernel_size,\n",
    "                                padding=padding,\n",
    "                                kernel_regularizer=kernel_regularizer,\n",
    "                                activation='relu',\n",
    "                                name=model_name + '_conv_' + str(n+1)\n",
    "                               )(x)\n",
    "        if momentum > 0.0:\n",
    "            x = keras.layers.BatchNormalization(momentum=momentum,\n",
    "                                                name=model_name + '_bnorm_' + str(n+1)\n",
    "                                               )(x)\n",
    "    \n",
    "    # dropout layer\n",
    "    if dropout > 0.0:\n",
    "        x = keras.layers.Dropout(rate=dropout, name=model_name + '_drop')(x)\n",
    "        \n",
    "    # flatten\n",
    "    x = keras.layers.Flatten(name=model_name + '_flat')(x)\n",
    "    \n",
    "    # output\n",
    "    h11 = keras.layers.Dense(units=1,\n",
    "                             activation='relu',\n",
    "                             name='h11_output'\n",
    "                            )(x)\n",
    "    \n",
    "    # define the model\n",
    "    model = keras.models.Model(inputs=I, outputs=h11, name=model_name)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='mse',\n",
    "                  metrics=['mse', 'mae']\n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_small = seq_model(input_shape=input_shape,\n",
    "                             model_name='seq_small',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[180, 100, 40, 20],\n",
    "                             kernel_size=(3,3),\n",
    "                             dropout=0.3,\n",
    "                             l1_reg=1.0e-5,\n",
    "                             l2_reg=1.0e-5\n",
    "                            )\n",
    "sequential_large = seq_model(input_shape=input_shape,\n",
    "                             model_name='seq_large',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[180, 100, 40, 20],\n",
    "                             kernel_size=(5,5),\n",
    "                             dropout=0.3,\n",
    "                             l1_reg=1.0e-5,\n",
    "                             l2_reg=1.0e-5\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be visualised using `keras` utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image\n",
    "\n",
    "sequential_dot = keras.utils.model_to_dot(sequential_small,\n",
    "                                          show_shapes=True,\n",
    "                                          dpi=150\n",
    "                                         )\n",
    "sequential_dot.write_pdf('./img/seq_arch_h11.pdf')\n",
    "#Image(sequential_dot.create_png(), width=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./dat', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80% Training Data w/ Outliers (small kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_small\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_small_input (InputLayer) [(None, 12, 15, 1)]       0         \n",
      "_________________________________________________________________\n",
      "seq_small_conv_1 (Conv2D)    (None, 12, 15, 180)       1800      \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_1 (BatchNorm (None, 12, 15, 180)       720       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_2 (Conv2D)    (None, 12, 15, 100)       162100    \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_2 (BatchNorm (None, 12, 15, 100)       400       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_3 (Conv2D)    (None, 12, 15, 40)        36040     \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_3 (BatchNorm (None, 12, 15, 40)        160       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_4 (Conv2D)    (None, 12, 15, 20)        7220      \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_4 (BatchNorm (None, 12, 15, 20)        80        \n",
      "_________________________________________________________________\n",
      "seq_small_drop (Dropout)     (None, 12, 15, 20)        0         \n",
      "_________________________________________________________________\n",
      "seq_small_flat (Flatten)     (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "h11_output (Dense)           (None, 1)                 3601      \n",
      "=================================================================\n",
      "Total params: 212,121\n",
      "Trainable params: 211,441\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Training 80% data w/ outliers (small kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/sequential_small_out_80_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "sequential_small.summary()\n",
    "\n",
    "print('Training 80% data w/ outliers (small kernel)')\n",
    "\n",
    "# define the model\n",
    "sequential_small = seq_model(input_shape=input_shape,\n",
    "                            model_name='seq_small',\n",
    "                            learning_rate=0.001,\n",
    "                            filters=[180, 100, 40, 20],\n",
    "                            kernel_size=(3,3),\n",
    "                            dropout=0.3,\n",
    "                            l1_reg=1.0e-5,\n",
    "                            l2_reg=1.0e-5\n",
    "                           )\n",
    "seq_small_out_80 = sequential_small.fit(x=mat_out_train_80,\n",
    "                                        y=lab_out_train_80,\n",
    "                                        batch_size=32,\n",
    "                                        epochs=10,\n",
    "                                        verbose=0,\n",
    "                                        callbacks=callbacks,\n",
    "                                        validation_data=(mat_out_val_80, lab_out_val_80)\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 63.37%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(sequential_small.predict(mat_out_test_80)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_out_test_80.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/seq_small_out_80_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(seq_small_out_80.history, './dat/seq_small_out_80_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80% Training Data w/o Outliers (small kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_small\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_small_input (InputLayer) [(None, 12, 15, 1)]       0         \n",
      "_________________________________________________________________\n",
      "seq_small_conv_1 (Conv2D)    (None, 12, 15, 180)       1800      \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_1 (BatchNorm (None, 12, 15, 180)       720       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_2 (Conv2D)    (None, 12, 15, 100)       162100    \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_2 (BatchNorm (None, 12, 15, 100)       400       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_3 (Conv2D)    (None, 12, 15, 40)        36040     \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_3 (BatchNorm (None, 12, 15, 40)        160       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_4 (Conv2D)    (None, 12, 15, 20)        7220      \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_4 (BatchNorm (None, 12, 15, 20)        80        \n",
      "_________________________________________________________________\n",
      "seq_small_drop (Dropout)     (None, 12, 15, 20)        0         \n",
      "_________________________________________________________________\n",
      "seq_small_flat (Flatten)     (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "h11_output (Dense)           (None, 1)                 3601      \n",
      "=================================================================\n",
      "Total params: 212,121\n",
      "Trainable params: 211,441\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Training 80% data w/o outliers (small kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/sequential_small_noout_80_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "sequential_small.summary()\n",
    "\n",
    "print('Training 80% data w/o outliers (small kernel)')\n",
    "\n",
    "# define the model\n",
    "sequential_small = seq_model(input_shape=input_shape,\n",
    "                             model_name='seq_small',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[180, 100, 40, 20],\n",
    "                             kernel_size=(3,3),\n",
    "                             dropout=0.3,\n",
    "                             l1_reg=1.0e-5,\n",
    "                             l2_reg=1.0e-5\n",
    "                            )\n",
    "seq_small_noout_80 = sequential_small.fit(x=mat_noout_train_80,\n",
    "                                          y=lab_noout_train_80,\n",
    "                                          batch_size=32,\n",
    "                                          epochs=10,\n",
    "                                          verbose=0,\n",
    "                                          callbacks=callbacks,\n",
    "                                          validation_data=(mat_noout_val_80, lab_noout_val_80)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(sequential_small.predict(mat_noout_test_80)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_noout_test_80.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/seq_small_noout_80_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(seq_small_noout_80.history, './dat/seq_small_noout_80_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30% Training Data w/ Outliers (small kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_small\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_small_input (InputLayer) [(None, 12, 15, 1)]       0         \n",
      "_________________________________________________________________\n",
      "seq_small_conv_1 (Conv2D)    (None, 12, 15, 180)       1800      \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_1 (BatchNorm (None, 12, 15, 180)       720       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_2 (Conv2D)    (None, 12, 15, 100)       162100    \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_2 (BatchNorm (None, 12, 15, 100)       400       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_3 (Conv2D)    (None, 12, 15, 40)        36040     \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_3 (BatchNorm (None, 12, 15, 40)        160       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_4 (Conv2D)    (None, 12, 15, 20)        7220      \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_4 (BatchNorm (None, 12, 15, 20)        80        \n",
      "_________________________________________________________________\n",
      "seq_small_drop (Dropout)     (None, 12, 15, 20)        0         \n",
      "_________________________________________________________________\n",
      "seq_small_flat (Flatten)     (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "h11_output (Dense)           (None, 1)                 3601      \n",
      "=================================================================\n",
      "Total params: 212,121\n",
      "Trainable params: 211,441\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Training 30% data w/ outliers (small kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/sequential_small_out_30_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "sequential_small.summary()\n",
    "\n",
    "print('Training 30% data w/ outliers (small kernel)')\n",
    "\n",
    "# define the model\n",
    "sequential_small = seq_model(input_shape=input_shape,\n",
    "                             model_name='seq_small',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[180, 100, 40, 20],\n",
    "                             kernel_size=(3,3),\n",
    "                             dropout=0.3,\n",
    "                             l1_reg=1.0e-5,\n",
    "                             l2_reg=1.0e-5\n",
    "                            )\n",
    "seq_small_out_30 = sequential_small.fit(x=mat_out_train_30,\n",
    "                                        y=lab_out_train_30,\n",
    "                                        batch_size=32,\n",
    "                                        epochs=10,\n",
    "                                        verbose=0,\n",
    "                                        callbacks=callbacks,\n",
    "                                        validation_data=(mat_out_val_30, lab_out_val_30)\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 9.48%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(sequential_small.predict(mat_out_test_30)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_out_test_30.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true,\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/seq_small_out_30_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(seq_small_out_30.history, './dat/seq_small_out_30_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30% Training Data w/o Outliers (small kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_small\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_small_input (InputLayer) [(None, 12, 15, 1)]       0         \n",
      "_________________________________________________________________\n",
      "seq_small_conv_1 (Conv2D)    (None, 12, 15, 180)       1800      \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_1 (BatchNorm (None, 12, 15, 180)       720       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_2 (Conv2D)    (None, 12, 15, 100)       162100    \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_2 (BatchNorm (None, 12, 15, 100)       400       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_3 (Conv2D)    (None, 12, 15, 40)        36040     \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_3 (BatchNorm (None, 12, 15, 40)        160       \n",
      "_________________________________________________________________\n",
      "seq_small_conv_4 (Conv2D)    (None, 12, 15, 20)        7220      \n",
      "_________________________________________________________________\n",
      "seq_small_bnorm_4 (BatchNorm (None, 12, 15, 20)        80        \n",
      "_________________________________________________________________\n",
      "seq_small_drop (Dropout)     (None, 12, 15, 20)        0         \n",
      "_________________________________________________________________\n",
      "seq_small_flat (Flatten)     (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "h11_output (Dense)           (None, 1)                 3601      \n",
      "=================================================================\n",
      "Total params: 212,121\n",
      "Trainable params: 211,441\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Training 30% data w/o outliers (small kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/sequential_small_noout_30_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "sequential_small.summary()\n",
    "\n",
    "print('Training 30% data w/o outliers (small kernel)')\n",
    "\n",
    "# define the model\n",
    "sequential_small = seq_model(input_shape=input_shape,\n",
    "                             model_name='seq_small',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[180, 100, 40, 20],\n",
    "                             kernel_size=(3,3),\n",
    "                             dropout=0.3,\n",
    "                             l1_reg=1.0e-5,\n",
    "                             l2_reg=1.0e-5\n",
    "                            )\n",
    "seq_small_noout_30 = sequential_small.fit(x=mat_noout_train_30,\n",
    "                                          y=lab_noout_train_30,\n",
    "                                          batch_size=32,\n",
    "                                          epochs=10,\n",
    "                                          verbose=0,\n",
    "                                          callbacks=callbacks,\n",
    "                                          validation_data=(mat_noout_val_30, lab_noout_val_30)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 1.36%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(sequential_small.predict(mat_noout_test_30)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_noout_test_30.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/seq_small_noout_30_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(seq_small_noout_30.history, './dat/seq_small_noout_30_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80% Training Data w/ Outliers (large kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_large\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_large_input (InputLayer) [(None, 12, 15, 1)]       0         \n",
      "_________________________________________________________________\n",
      "seq_large_conv_1 (Conv2D)    (None, 12, 15, 180)       4680      \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_1 (BatchNorm (None, 12, 15, 180)       720       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_2 (Conv2D)    (None, 12, 15, 100)       450100    \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_2 (BatchNorm (None, 12, 15, 100)       400       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_3 (Conv2D)    (None, 12, 15, 40)        100040    \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_3 (BatchNorm (None, 12, 15, 40)        160       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_4 (Conv2D)    (None, 12, 15, 20)        20020     \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_4 (BatchNorm (None, 12, 15, 20)        80        \n",
      "_________________________________________________________________\n",
      "seq_large_drop (Dropout)     (None, 12, 15, 20)        0         \n",
      "_________________________________________________________________\n",
      "seq_large_flat (Flatten)     (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "h11_output (Dense)           (None, 1)                 3601      \n",
      "=================================================================\n",
      "Total params: 579,801\n",
      "Trainable params: 579,121\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Training 80% data w/ outliers (large kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/sequential_large_out_80_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "sequential_large.summary()\n",
    "\n",
    "print('Training 80% data w/ outliers (large kernel)')\n",
    "\n",
    "# define the model\n",
    "sequential_large = seq_model(input_shape=input_shape,\n",
    "                             model_name='seq_large',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[180, 100, 40, 20],\n",
    "                             kernel_size=(5,5),\n",
    "                             dropout=0.3,\n",
    "                             l1_reg=1.0e-5,\n",
    "                             l2_reg=1.0e-5\n",
    "                            )\n",
    "seq_large_out_80 = sequential_large.fit(x=mat_out_train_80,\n",
    "                                        y=lab_out_train_80,\n",
    "                                        batch_size=32,\n",
    "                                        epochs=10,\n",
    "                                        verbose=0,\n",
    "                                        callbacks=callbacks,\n",
    "                                        validation_data=(mat_out_val_80, lab_out_val_80)\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 4.56%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(sequential_large.predict(mat_out_test_80)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_out_test_80.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/seq_large_out_80_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(seq_large_out_80.history, './dat/seq_large_out_80_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80% Training Data w/o Outliers (large kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_large\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_large_input (InputLayer) [(None, 12, 15, 1)]       0         \n",
      "_________________________________________________________________\n",
      "seq_large_conv_1 (Conv2D)    (None, 12, 15, 180)       4680      \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_1 (BatchNorm (None, 12, 15, 180)       720       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_2 (Conv2D)    (None, 12, 15, 100)       450100    \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_2 (BatchNorm (None, 12, 15, 100)       400       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_3 (Conv2D)    (None, 12, 15, 40)        100040    \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_3 (BatchNorm (None, 12, 15, 40)        160       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_4 (Conv2D)    (None, 12, 15, 20)        20020     \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_4 (BatchNorm (None, 12, 15, 20)        80        \n",
      "_________________________________________________________________\n",
      "seq_large_drop (Dropout)     (None, 12, 15, 20)        0         \n",
      "_________________________________________________________________\n",
      "seq_large_flat (Flatten)     (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "h11_output (Dense)           (None, 1)                 3601      \n",
      "=================================================================\n",
      "Total params: 579,801\n",
      "Trainable params: 579,121\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Training 80% data w/o outliers (large kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/sequential_large_noout_80_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "sequential_large.summary()\n",
    "\n",
    "print('Training 80% data w/o outliers (large kernel)')\n",
    "\n",
    "# define the model\n",
    "sequential_large = seq_model(input_shape=input_shape,\n",
    "                             model_name='seq_large',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[180, 100, 40, 20],\n",
    "                             kernel_size=(5,5),\n",
    "                             dropout=0.3,\n",
    "                             l1_reg=1.0e-5,\n",
    "                             l2_reg=1.0e-5\n",
    "                            )\n",
    "seq_large_noout_80 = sequential_large.fit(x=mat_noout_train_80,\n",
    "                                          y=lab_noout_train_80,\n",
    "                                          batch_size=32,\n",
    "                                          epochs=10,\n",
    "                                          verbose=0,\n",
    "                                          callbacks=callbacks,\n",
    "                                          validation_data=(mat_noout_val_80, lab_noout_val_80)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(sequential_large.predict(mat_noout_test_80)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_noout_test_80.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/seq_large_noout_80_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(seq_large_noout_80.history, './dat/seq_large_noout_80_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30% Training Data w/ Outliers (large kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_large\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_large_input (InputLayer) [(None, 12, 15, 1)]       0         \n",
      "_________________________________________________________________\n",
      "seq_large_conv_1 (Conv2D)    (None, 12, 15, 180)       4680      \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_1 (BatchNorm (None, 12, 15, 180)       720       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_2 (Conv2D)    (None, 12, 15, 100)       450100    \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_2 (BatchNorm (None, 12, 15, 100)       400       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_3 (Conv2D)    (None, 12, 15, 40)        100040    \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_3 (BatchNorm (None, 12, 15, 40)        160       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_4 (Conv2D)    (None, 12, 15, 20)        20020     \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_4 (BatchNorm (None, 12, 15, 20)        80        \n",
      "_________________________________________________________________\n",
      "seq_large_drop (Dropout)     (None, 12, 15, 20)        0         \n",
      "_________________________________________________________________\n",
      "seq_large_flat (Flatten)     (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "h11_output (Dense)           (None, 1)                 3601      \n",
      "=================================================================\n",
      "Total params: 579,801\n",
      "Trainable params: 579,121\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Training 30% data w/ outliers (large kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/sequential_large_out_30_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "sequential_large.summary()\n",
    "\n",
    "print('Training 30% data w/ outliers (large kernel)')\n",
    "\n",
    "# define the model\n",
    "sequential_large = seq_model(input_shape=input_shape,\n",
    "                             model_name='seq_large',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[180, 100, 40, 20],\n",
    "                             kernel_size=(5,5),\n",
    "                             dropout=0.3,\n",
    "                             l1_reg=1.0e-5,\n",
    "                             l2_reg=1.0e-5\n",
    "                            )\n",
    "seq_large_out_30 = sequential_large.fit(x=mat_out_train_30,\n",
    "                                        y=lab_out_train_30,\n",
    "                                        batch_size=32,\n",
    "                                        epochs=10,\n",
    "                                        verbose=0,\n",
    "                                        callbacks=callbacks,\n",
    "                                        validation_data=(mat_out_val_30, lab_out_val_30)\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 21.40%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(sequential_large.predict(mat_out_test_30)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_out_test_30.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/seq_large_out_30_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(seq_large_out_30.history, './dat/seq_large_out_30_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30% Training Data w/o Outliers (large kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_large\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_large_input (InputLayer) [(None, 12, 15, 1)]       0         \n",
      "_________________________________________________________________\n",
      "seq_large_conv_1 (Conv2D)    (None, 12, 15, 180)       4680      \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_1 (BatchNorm (None, 12, 15, 180)       720       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_2 (Conv2D)    (None, 12, 15, 100)       450100    \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_2 (BatchNorm (None, 12, 15, 100)       400       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_3 (Conv2D)    (None, 12, 15, 40)        100040    \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_3 (BatchNorm (None, 12, 15, 40)        160       \n",
      "_________________________________________________________________\n",
      "seq_large_conv_4 (Conv2D)    (None, 12, 15, 20)        20020     \n",
      "_________________________________________________________________\n",
      "seq_large_bnorm_4 (BatchNorm (None, 12, 15, 20)        80        \n",
      "_________________________________________________________________\n",
      "seq_large_drop (Dropout)     (None, 12, 15, 20)        0         \n",
      "_________________________________________________________________\n",
      "seq_large_flat (Flatten)     (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "h11_output (Dense)           (None, 1)                 3601      \n",
      "=================================================================\n",
      "Total params: 579,801\n",
      "Trainable params: 579,121\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Training 30% data w/o outliers (large kernel)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('./mod/sequential_large_noout_30_h11.h5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=0,\n",
    "                                             save_best_only=True\n",
    "                                            ),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=80,\n",
    "                                               verbose=0,\n",
    "                                               min_lr=1.0e-6\n",
    "                                              ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=200,\n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=0\n",
    "                                          )\n",
    "            ]\n",
    "\n",
    "sequential_large.summary()\n",
    "\n",
    "print('Training 30% data w/o outliers (large kernel)')\n",
    "\n",
    "# define the model\n",
    "sequential_large = seq_model(input_shape=input_shape,\n",
    "                             model_name='seq_large',\n",
    "                             learning_rate=0.001,\n",
    "                             filters=[180, 100, 40, 20],\n",
    "                             kernel_size=(5,5),\n",
    "                             dropout=0.3,\n",
    "                             l1_reg=1.0e-5,\n",
    "                             l2_reg=1.0e-5\n",
    "                            )\n",
    "seq_large_noout_30 = sequential_large.fit(x=mat_noout_train_30,\n",
    "                                          y=lab_noout_train_30,\n",
    "                                          batch_size=32,\n",
    "                                          epochs=10,\n",
    "                                          verbose=0,\n",
    "                                          callbacks=callbacks,\n",
    "                                          validation_data=(mat_noout_val_30, lab_noout_val_30)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the take a look at the accuracy of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for h_11: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# predictions\n",
    "h11_pred = np.rint(sequential_large.predict(mat_noout_test_30)).astype(int).reshape(-1,)\n",
    "\n",
    "# true values\n",
    "h11_true = lab_noout_test_30.astype(int).reshape(-1,)\n",
    "\n",
    "# accuracy\n",
    "h11_acc = np.mean((h11_pred == h11_true).astype(int))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'h11_pred': h11_pred,\n",
    "               'h11_true': h11_true\n",
    "              }\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.to_csv('./dat/seq_large_noout_30_h11.csv')\n",
    "\n",
    "# save history\n",
    "joblib.dump(seq_large_noout_30.history, './dat/seq_large_noout_30_h11.pkl')\n",
    "\n",
    "# print accuracy\n",
    "print('Accuracy for h_11: {:.2f}%'.format(h11_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
