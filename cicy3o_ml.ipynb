{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Complete Intersection Calabi-Yau Manifolds\n",
    "\n",
    "After the preanalysis and the **feature selection**, we no proceed with the ML analysis using different algorithms to evaluate the best predictions for the **Hodge numbers** of CICY 3-folds. We first print debug information on the system and then load the previously generated datasets. We then move to the analysis using _Scikit-learn_ as reference library. In particular we use:\n",
    "\n",
    "- [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) to have a starting point,\n",
    "- [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) to check the difference from the linear model using a **L1** regularization,\n",
    "- [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) to implement **L2** regularization to the linear model,\n",
    "- [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet) to see whether **L1** and **L2** can be implemented together,\n",
    "- [LinearSVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR) to implement **support vectors** with a linear kernel,\n",
    "- [SVR (with Gaussian kernel)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) to introduce a kernel function,\n",
    "- [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor) to use forests of **decision trees** for the predictions,\n",
    "- [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor) to boost single decision trees using gradient descent (in this case we will also study the **learning curve**).\n",
    "\n",
    "In the case of the **support vector machine** with Gaussian kernel we will also compare the results with [_Bull et al._](https://arxiv.org/abs/1806.03121)): we will check that the results are reproducible and that feature engineering can help in improving the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infrastructure\n",
    "\n",
    "We print information about the current OS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.libos import InfoOS\n",
    "\n",
    "print('Current OS:                  {} (kernel release: {}, architecture: {})'.format(InfoOS().os, InfoOS().kernel, InfoOS().arch))\n",
    "print('Number of available threads: {:d}'.format(InfoOS().threads))\n",
    "print('Current CPU frequency:       {:.0f} MHz (max: {:.0f} MHz)'.format(InfoOS().freq, InfoOS().freqm))\n",
    "print('Available RAM memory:        {:d} MB (tot: {:d} MB)'.format(InfoOS().vmav, InfoOS().vmtot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future use, we establish early in the notebook the number of maximum jobs that every algorithm can take concurrently. Thus, if we want to run parallel notebooks with different jobs, we will not encounter issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_jobs = int(InfoOS().threads) #---------- very intensive but faster\n",
    "n_jobs = int(InfoOS().threads / 2) #------ still fast enough but less intensive (only 50% of available threads are occupied)\n",
    "#n_jobs = int(InfoOS().threads / 4) #------ slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then print information on the current GPU setup (if available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We import the Python modules we use and print their versions to keep track of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import random     as rnd\n",
    "import sklearn    as skl\n",
    "import skopt      as sko\n",
    "import numpy      as np\n",
    "import pandas     as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow       import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning) # ignore user warnings: nothing that I can really do anything about it...\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=12)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# print the version of the modules\n",
    "print('Python version: {:d}.{:d}'      .format(sys.version_info.major, sys.version_info.minor))\n",
    "print('Matplot version: {}'            .format(mpl.__version__))\n",
    "print('Numpy version: {}'              .format(np.__version__))\n",
    "print('Pandas version: {}'             .format(pd.__version__))\n",
    "print('Scikit-learn version: {}'       .format(skl.__version__))\n",
    "print('Scikit-optimize version: {}'    .format(sko.__version__))\n",
    "print('Tensorflow version: {}'         .format(tf.__version__))\n",
    "print('Keras version: {} (backend: {})'.format(keras.__version__, K.backend()))\n",
    "\n",
    "# fix random_seed\n",
    "RAND = 42\n",
    "rnd.seed(RAND)\n",
    "np.random.seed(RAND)\n",
    "tf.random.set_seed(RAND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Preparation\n",
    "\n",
    "in order to save the results of the analysis, we define where to store images, log files and models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "\n",
    "ROOT_DIR = '.' #-------------------------------------------------- root directory\n",
    "IMG_DIR  = 'img' #------------------------------------------------ directory of images\n",
    "MOD_DIR  = 'models' #--------------------------------------------- directory of saved models\n",
    "LOG_DIR  = 'log' #------------------------------------------------ directory of logs\n",
    "\n",
    "DB_NAME = 'cicy3o' #---------------------------------------------- name of the dataset\n",
    "DB_FILE = DB_NAME + '_analysis.h5' #------------------------------ full name with extension\n",
    "DB_PATH = path.join(ROOT_DIR, DB_FILE) #-------------------------- full path of the dataset\n",
    "DB_DIR  = 'original' if DB_NAME == 'cicy3o' else 'favourable' #--- subdir where to store images, models, logs\n",
    "\n",
    "# define full paths\n",
    "IMG_PATH = path.join(ROOT_DIR, IMG_DIR, DB_DIR)\n",
    "MOD_PATH = path.join(ROOT_DIR, MOD_DIR, DB_DIR)\n",
    "LOG_PATH = path.join(ROOT_DIR, LOG_DIR, DB_DIR)\n",
    "\n",
    "# create directories if non existent\n",
    "if not path.isdir(IMG_PATH):\n",
    "    makedirs(IMG_PATH, exist_ok=True)\n",
    "if not path.isdir(MOD_PATH):\n",
    "    makedirs(MOD_PATH, exist_ok=True)\n",
    "if not path.isdir(LOG_PATH):\n",
    "    makedirs(LOG_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a log file to store debug and related information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from mltools.liblog import create_logfile\n",
    "\n",
    "path_to_log = path.join(LOG_PATH,\n",
    "                        DB_NAME + '_ml.log'\n",
    "                       )\n",
    "log = create_logfile(path_to_log,\n",
    "                     name=DB_NAME + '_ml',\n",
    "                     level=logging.DEBUG\n",
    "                    )\n",
    "\n",
    "# these lines provide the same setup also for the Jupyter logging\n",
    "logger = logging.getLogger() #------------------------------------------------- get the current logging session\n",
    "\n",
    "fmt = logging.Formatter('%(asctime)s: %(levelname)s ==> %(message)s') #-------- customise the formatting options\n",
    "\n",
    "handler = logging.StreamHandler() #-------------------------------------------- handle the stream to the default (stderr)\n",
    "handler.setLevel(logging.DEBUG) #---------------------------------------------- print everything\n",
    "handler.setFormatter(fmt) #---------------------------------------------------- set the formatting options\n",
    "\n",
    "logger.handlers = [handler] #-------------------------------------------------- override the default stream\n",
    "\n",
    "# we are ready to go!\n",
    "log.info('New logging session started. Log is at {}.'.format(path_to_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally set the _memory growth_ property of the GPU in order to avoid overflowing its RAM memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU') #--------------------------------------- list of physical GPUs\n",
    "\n",
    "if gpus: #----------------------------------------------------------------------------------------- set memory growth only if GPU is active\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True) #---------------------------------- set memory growth\n",
    "            \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU') #------------------------ list of logical devices\n",
    "        print('GPU setup: {:d} physical GPUs, {:d} logical GPUs.'.format(len(gpus),\n",
    "                                                                         len(logical_gpus)\n",
    "                                                                        )\n",
    "             )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPUs in the setup!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "We first load the dataset we built during the preanalysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "if path.isfile(DB_PATH):\n",
    "    df = pd.read_hdf(DB_PATH)\n",
    "    log.debug('Database loaded.')\n",
    "    log.info('Shape is {:d} rows x {:d} columns.'.format(df.shape[0], df.shape[1]))\n",
    "else:\n",
    "    log.error('Cannot load database from {}!'.format(DB_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the `dtypes` and the name of the keys inside the dataframe as a reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Format Extraction\n",
    "\n",
    "We now extract the needed features from the sparse format in which they are stores. We also contextually build the feature matrices and the labels vectors needed in the analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.libtransformer import ExtractTensor\n",
    "\n",
    "# extract the labels\n",
    "h11        = df['h11'].values\n",
    "h21        = df['h21'].values\n",
    "\n",
    "# extract the scalar feature\n",
    "num_cp     = np.reshape(df['num_cp'].values, (-1,1)) # num_cp needs to be reshaped because it is a single feature\n",
    "\n",
    "# extract the vector features\n",
    "dim_cp     = np.array(ExtractTensor(flatten=True).fit_transform(df['dim_cp']))\n",
    "dim_h0_amb = np.array(ExtractTensor(flatten=True).fit_transform(df['dim_h0_amb']))\n",
    "\n",
    "# extract the tensor features\n",
    "matrix     = np.array(ExtractTensor(flatten=True).fit_transform(df['matrix']))\n",
    "pca        = np.array(ExtractTensor(flatten=True).fit_transform(df['pca']))\n",
    "\n",
    "# build the feature engineered sets\n",
    "feat_h11_nopca = np.c_[num_cp, dim_cp]\n",
    "feat_h21_nopca = np.c_[num_cp, dim_cp, dim_h0_amb]\n",
    "\n",
    "feat_h11_pca   = np.c_[feat_h11_nopca, pca]\n",
    "feat_h21_pca   = np.c_[feat_h21_nopca, pca]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Strategy\n",
    "\n",
    "We now define the validation strategy and split the dataset into training, validation and test sets.\n",
    "\n",
    "We will take out 10% of the dataset to be our **test set**. For the remaining 90% of the dataset, we will use cross-validation with 9 splits (using **KFold** splits) throughout the notebook. At the end of the day we therefore use 10% of the samples as test set, 10% as validation (in 9 folds) and effectively 80% for training.\n",
    "\n",
    "Apart from the case of linear regression, we use Bayesan optimization (from the [_Scikit-optimize_](https://scikit-optimize.github.io/stable/index.html) library) of the hyperparameters as it helps in finding a \"direction\" in the procedure (as opposed to a random search) and avoids useless grid searches which for large hyperparameter spaces are unfeasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# define the cross-validation splits\n",
    "cv = KFold(n_splits=9, shuffle=False)\n",
    "\n",
    "# divide into training and test sets\n",
    "matrix_train, matrix_test, \\\n",
    "num_cp_train, num_cp_test, \\\n",
    "feat_h11_nopca_train, feat_h11_nopca_test, \\\n",
    "feat_h21_nopca_train, feat_h21_nopca_test, \\\n",
    "feat_h11_pca_train, feat_h11_pca_test, \\\n",
    "feat_h21_pca_train, feat_h21_pca_test, \\\n",
    "h11_train, h11_test, \\\n",
    "h21_train, h21_test = train_test_split(matrix, num_cp, feat_h11_nopca, feat_h21_nopca, feat_h11_pca, feat_h21_nopca, h11, h21,\n",
    "                                       test_size=0.1,\n",
    "                                       shuffle=False\n",
    "                                      )\n",
    "\n",
    "log.debug('Train set size: {:d}'.format(np.shape(matrix_train)[0]))\n",
    "log.debug('Test set size: {:d}'.format(np.shape(matrix_test)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the analysis that follows we will then study the accuracy of the algorithms both on validation and test sets and we will plot the predictions made by each algorithm. We will also clearly print the best fitting hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty(dct, indent=True):\n",
    "    '''\n",
    "    Pretty print the dictionary of best parameters.\n",
    "    \n",
    "    Required argument:\n",
    "        dct:    the dictionary to pretty print.\n",
    "        \n",
    "    Optional argument:\n",
    "        indent: whether to indent the printed output.\n",
    "    '''\n",
    "    \n",
    "    for key, value in dct.items():\n",
    "        if indent:\n",
    "            print('    {} = {}'.format(key, value))\n",
    "        else:\n",
    "            print('{} = {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide a way to visualise the predictions by comparing the predictions as function of a (scalar) base feature (e.g.: `num_cp`) with respect to the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(base_feature, label):\n",
    "    '''\n",
    "    Returns unique values and counts of the label as a function of the base_feature.\n",
    "    \n",
    "    Required arguments:\n",
    "        base_feature: the feature considered as base for the comparison,\n",
    "        label:        the label we are interested in comparing.\n",
    "    \n",
    "    Yields:\n",
    "        [ unique value of base_feature, unique value of label, count ].\n",
    "    '''\n",
    "    \n",
    "    for n in np.sort(np.unique(base_feature)):\n",
    "        uniques, counts = np.unique(label[np.argwhere(base_feature == n)[:,0]], return_counts=True)\n",
    "        \n",
    "        for u, c in np.c_[uniques, counts]:\n",
    "            yield [n, u, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this kind of comparison is technically meaningful only when the predictions are made by the `base_feature` itself (e.g.: when training and predicting starting from `num_cp`). However we would like to show the distribution of the predicted labels as a function of a scalar feature \"as representative\" of the tensor-like feature on which the algorithms was trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "We now consider the simplest algorithm in the analysis. We will perform linear regression on the data and evaluate the performace: the cost function is the simple **mean squared error** $J(\\theta) = \\frac{\\vert\\vert y - X \\theta^T \\vert\\vert^2}{2 N}$. In this case the number of hyperparameters is very small and we can use a **grid search** to explore the entire optimization space. Specifically we will focus on:\n",
    "\n",
    "- `fit_intercept` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `normalize` $\\in \\lbrace 0, 1 \\rbrace$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics         import make_scorer\n",
    "from mltools.libscore        import accuracy, Score, ViewCV\n",
    "from mltools.libplot         import Plot\n",
    "\n",
    "log.info('Trainining linear regression...')\n",
    "\n",
    "rounding      = np.floor #------------------------------------------------ choose a rounding function\n",
    "search_params = {'fit_intercept': [0, 1],\n",
    "                 'normalize':     [0, 1]\n",
    "                } #------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = GridSearchCV(LinearRegression(), #------------------------ choose the base estimator\n",
    "                             param_grid=search_params,\n",
    "                             scoring=make_scorer(accuracy,\n",
    "                                                 greater_is_better=True,\n",
    "                                                 rounding=rounding\n",
    "                                                ), #---------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                             n_jobs=n_jobs,\n",
    "                             refit=True,\n",
    "                             cv=cv\n",
    "                            )\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# MATRIX                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nMATRIX\\n')\n",
    "\n",
    "estimator.fit(matrix_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(matrix_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "# plot.hist2D(pred_score_h11.error(),\n",
    "#             axis=2,\n",
    "#             title='Distance of the Predictions from the Real Value',\n",
    "#             legend='$h_{11}$',\n",
    "#             xlabel='error difference',\n",
    "#             ylabel='#',\n",
    "#             binstep=5\n",
    "#            )\n",
    "# plot.hist2D(pred_score_h21.error(),\n",
    "#             axis=2,\n",
    "#             title='Distance of the Predictions from the Real Value',\n",
    "#             legend='$h_{21}$',\n",
    "#             xlabel='error difference',\n",
    "#             ylabel='#',\n",
    "#             binstep=5\n",
    "#            )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lin_reg_mat_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lin_reg_mat_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# NUM_CP                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nNUM_CP\\n')\n",
    "\n",
    "estimator.fit(num_cp_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "coef_h11   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h11 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(num_cp_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "coef_h21   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h21 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: x,\n",
    "             fmt='b-',\n",
    "             axis=0,\n",
    "             legend='$h_{11} = $ num_cp',\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h11 + coef_h11 * x,\n",
    "             fmt='r--',\n",
    "             axis=0,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h11, coef_h11[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h21 + coef_h21 * x,\n",
    "             fmt='r--',\n",
    "             axis=1,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h21, coef_h21[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=5\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=5\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lin_reg_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lin_reg_num_cp_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES ONLY     #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES ONLY\\n')\n",
    "\n",
    "estimator.fit(feat_h11_nopca_train, h11_train) #------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_nopca_train, h21_train) #------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lin_reg_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lin_reg_nopca_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES AND PCA  #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES AND PCA\\n')\n",
    "\n",
    "estimator.fit(feat_h11_pca_train, h11_train) #--------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_pca_train, h21_train) #--------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lin_reg_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lin_reg_pca_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of linear regression we are not plotting the error difference of the run with only the configuration matrix as input. As it is also visible from the plot of $h_{11}$ and $h_{21}$ vs. `num_cp` for that run, there is one predictions which is off by a factor $10^{13}$: there might be a bug somewhere, but for the time being we were not able to find it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "\n",
    "We then consider a variation on the linear regression introducing **L1** regularization. In this case the cost function is the usual **mean squared error** of the linear regression to which we add $\\Delta J(\\theta) = \\alpha * \\vert\\vert \\theta \\vert\\vert$. In this case we will control a slightly higher number of hyperparameters:\n",
    "\n",
    "- `fit_intercept` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `normalize` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `alpha` $\\in \\left[ 10^{-6}, 10^2 \\right]$,\n",
    "- `positive` $\\in \\lbrace 0, 1 \\rbrace$ (forces coefficients to be positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from skopt                import BayesSearchCV\n",
    "from skopt.space          import Integer, Real\n",
    "from sklearn.metrics      import make_scorer\n",
    "from mltools.libscore     import accuracy, Score, ViewCV\n",
    "from mltools.libplot      import Plot\n",
    "\n",
    "log.info('Trainining lasso...')\n",
    "\n",
    "rounding      = np.floor #---------------------------------------------------- choose a rounding function\n",
    "n_iter        = 100 #--------------------------------------------------------- the number of iteration of the Bayes search\n",
    "search_params = {'fit_intercept': Integer(0, 1),\n",
    "                 'normalize':     Integer(0, 1),\n",
    "                 'positive':      Integer(0, 1),\n",
    "                 'alpha':         Real(1.0e-6, 1.0e2, prior='log-uniform')\n",
    "                } #----------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(Lasso(max_iter=1e5, random_state=RAND), #------- choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #-------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# MATRIX                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nMATRIX\\n')\n",
    "\n",
    "estimator.fit(matrix_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(matrix_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='true values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lasso_mat_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lasso_mat_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# NUM_CP                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nNUM_CP\\n')\n",
    "\n",
    "estimator.fit(num_cp_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "coef_h11   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h11 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(num_cp_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "coef_h21   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h21 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: x,\n",
    "             fmt='b-',\n",
    "             axis=0,\n",
    "             legend='$h_{11} = $ num_cp',\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h11 + coef_h11 * x,\n",
    "             fmt='r--',\n",
    "             axis=0,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h11, coef_h11[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h21 + coef_h21 * x,\n",
    "             fmt='r--',\n",
    "             axis=1,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h21, coef_h21[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lasso_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lasso_num_cp_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES ONLY     #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES ONLY\\n')\n",
    "\n",
    "estimator.fit(feat_h11_nopca_train, h11_train) #------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_nopca_train, h21_train) #------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lasso_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lasso_nopca_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES AND PCA  #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES AND PCA\\n')\n",
    "\n",
    "estimator.fit(feat_h11_pca_train, h11_train) #--------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_pca_train, h21_train) #--------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lasso_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lasso_pca_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "We consider another variation on the linear regression introducing **L2** regularization. In this case the cost function is the **mean squared error** of the linear regression to which we add $\\Delta J(\\theta) = \\alpha * \\vert\\vert \\theta \\vert\\vert^2$. In this case we will control a slightly higher number of hyperparameters:\n",
    "\n",
    "- `fit_intercept` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `normalize` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `alpha` $\\in \\left[ 10^{-6}, 10^2 \\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from skopt                import BayesSearchCV\n",
    "from skopt.space          import Integer, Real\n",
    "from sklearn.metrics      import make_scorer\n",
    "from mltools.libscore     import accuracy, Score, ViewCV\n",
    "from mltools.libplot      import Plot\n",
    "\n",
    "log.info('Trainining ridge...')\n",
    "\n",
    "rounding      = np.floor #--------------------------------------------------- choose a rounding function\n",
    "n_iter        = 100 #-------------------------------------------------------- the number of iteration of the Bayes search\n",
    "search_params = {'fit_intercept': Integer(0, 1),\n",
    "                 'normalize':     Integer(0, 1),\n",
    "                 'alpha':         Real(1.0e-6, 1.0e2, prior='log-uniform')\n",
    "                } #---------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(Ridge(max_iter=1e5, random_state=RAND), #------ choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# MATRIX                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nMATRIX\\n')\n",
    "\n",
    "estimator.fit(matrix_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(matrix_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'ridge_mat_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'ridge_mat_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# NUM_CP                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nNUM_CP\\n')\n",
    "\n",
    "estimator.fit(num_cp_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "coef_h11   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h11 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(num_cp_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "coef_h21   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h21 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: x,\n",
    "             fmt='b-',\n",
    "             axis=0,\n",
    "             legend='$h_{11} = $ num_cp',\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h11 + coef_h11 * x,\n",
    "             fmt='r--',\n",
    "             axis=0,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h11, coef_h11[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h21 + coef_h21 * x,\n",
    "             fmt='r--',\n",
    "             axis=1,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h21, coef_h21[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'ridge_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'ridge_num_cp_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES ONLY     #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES ONLY\\n')\n",
    "\n",
    "estimator.fit(feat_h11_nopca_train, h11_train) #------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_nopca_train, h21_train) #------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'ridge_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'ridge_nopca_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES AND PCA  #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES AND PCA\\n')\n",
    "\n",
    "estimator.fit(feat_h11_pca_train, h11_train) #--------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_pca_train, h21_train) #--------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'ridge_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'ridge_pca_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Elastic Net](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)\n",
    "\n",
    "As a comparison to the two previous algorithms, we also train an elastic net which implements both **L1** and **L2** regularization. In this case the additional term to the cost function is $\\Delta J(\\theta) = \\alpha L_1 \\vert\\vert \\theta \\vert\\vert + \\frac{1}{2} \\alpha (1 - L_1) \\vert\\vert \\theta \\vert\\vert^2$. In the same way, we could have written $\\Delta J(\\theta) = a \\vert\\vert \\theta \\vert\\vert + b \\vert\\vert  \\theta \\vert\\vert^2$ where $\\alpha = a + b$ and $L_1 = \\frac{a}{a + b}$. The hyperparameters we control are:\n",
    "\n",
    "- `fit_intercept` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `normalize` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `positive` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `alpha` $\\in \\left[ 10^{-6}, 10^2 \\right]$,\n",
    "- `l1_ratio` $\\in \\left[ 0, 1 \\right]$ (the $L_1$ in the previous formulae),\n",
    "- `selection` $\\in \\lbrace random, cyclic \\rbrace$ (controls whether to update coefficients randomly or looping through the features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from skopt                import BayesSearchCV\n",
    "from skopt.space          import Integer, Real, Categorical\n",
    "from sklearn.metrics      import make_scorer\n",
    "from mltools.libscore     import accuracy, Score, ViewCV\n",
    "from mltools.libplot      import Plot\n",
    "\n",
    "log.info('Trainining elastic net...')\n",
    "\n",
    "rounding      = np.floor #----------------------------------------------------------------- choose a rounding function\n",
    "n_iter        = 100 #---------------------------------------------------------------------- the number of iteration of the Bayes search\n",
    "search_params = {'fit_intercept': Integer(0, 1),\n",
    "                 'normalize':     Integer(0, 1),\n",
    "                 'positive':      Integer(0, 1),\n",
    "                 'l1_ratio':      Real(0.0,    1.0,   prior='uniform'),\n",
    "                 'alpha':         Real(1.0e-6, 1.0e2, prior='log-uniform'),\n",
    "                 'selection':     Categorical(['random', 'cyclic'])\n",
    "                } #------------------------------------------------------------------------ define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(ElasticNet(max_iter=1e4, tol=1.0e-3, random_state=RAND), #--- choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #--------------------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# MATRIX                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nMATRIX\\n')\n",
    "\n",
    "estimator.fit(matrix_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(matrix_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'el_net_mat_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'el_net_mat_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# NUM_CP                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nNUM_CP\\n')\n",
    "\n",
    "estimator.fit(num_cp_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "coef_h11   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h11 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(num_cp_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "coef_h21   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h21 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: x,\n",
    "             fmt='b-',\n",
    "             axis=0,\n",
    "             legend='$h_{11} = $ num_cp',\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h11 + coef_h11 * x,\n",
    "             fmt='r--',\n",
    "             axis=0,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h11, coef_h11[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h21 + coef_h21 * x,\n",
    "             fmt='r--',\n",
    "             axis=1,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h21, coef_h21[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'el_net_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'el_net_num_cp_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES ONLY     #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES ONLY\\n')\n",
    "\n",
    "estimator.fit(feat_h11_nopca_train, h11_train) #------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_nopca_train, h21_train) #------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'el_net_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'el_net_nopca_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES AND PCA  #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES AND PCA\\n')\n",
    "\n",
    "estimator.fit(feat_h11_pca_train, h11_train) #--------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_pca_train, h21_train) #--------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'el_net_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'el_net_pca_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Linear SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html)\n",
    "\n",
    "The next step is to use a totally different kind of approach introducing **support vector machines** which use a different loss function to train the algorithm. Specifically they use so called **\"support vectors\"** and then approximate the training set using the distance from these landmarks as minimisation objective. We will first use the algorithm without a kernel function, thus the implementation is easier and the hyperparameter space is:\n",
    "\n",
    "- `epsilon` $\\in \\left[ 0.0, 10.0 \\right]$ (the $\\epsilon$ parameter in the $\\epsilon$-insensitive loss),\n",
    "- `C` $\\in \\left[ 10^{-3}, 10^2 \\right]$ (the regularization parameter),\n",
    "- `loss` $\\in \\lbrace epsilon\\_insensitive, squared\\_epsilon\\_insensitive \\rbrace$ (L1 and L2 losses),\n",
    "- `fit_intercept` $\\in \\lbrace 0, 1 \\rbrace$,\n",
    "- `intercept_scaling` $\\in \\left[ 10^{-2}, 10^2 \\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm      import LinearSVR\n",
    "from skopt            import BayesSearchCV\n",
    "from skopt.space      import Integer, Real, Categorical\n",
    "from sklearn.metrics  import make_scorer\n",
    "from mltools.libscore import accuracy, Score, ViewCV\n",
    "from mltools.libplot  import Plot\n",
    "\n",
    "log.info('Trainining linear svr...')\n",
    "\n",
    "rounding      = np.floor #--------------------------------------------------------- choose a rounding function\n",
    "n_iter        = 100 #-------------------------------------------------------------- the number of iteration of the Bayes search\n",
    "search_params = {'fit_intercept':     Integer(0, 1),\n",
    "                 'epsilon':           Real(0.0, 10.0, prior='uniform'),\n",
    "                 'C':                 Real(1.0e-3, 1.0e2, prior='log-uniform'),\n",
    "                 'intercept_scaling': Real(1.0e-2, 1.0e2, prior='log-uniform'),\n",
    "                 'loss':              Categorical(['epsilon_insensitive',\n",
    "                                                   'squared_epsilon_insensitive'\n",
    "                                                  ]\n",
    "                                                 )\n",
    "                } #---------------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(LinearSVR(max_iter=1e4, random_state=RAND), #-------- choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #------------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# MATRIX                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nMATRIX\\n')\n",
    "\n",
    "estimator.fit(matrix_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(matrix_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lin_svr_mat_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lin_svr_mat_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# NUM_CP                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nNUM_CP\\n')\n",
    "\n",
    "estimator.fit(num_cp_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "coef_h11   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h11 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(num_cp_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "coef_h21   = estimator.best_estimator_.coef_ #--------------------------------------------------- get angular coefficient\n",
    "interc_h21 = estimator.best_estimator_.intercept_ #---------------------------------------------- get intercept\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: x,\n",
    "             fmt='b-',\n",
    "             axis=0,\n",
    "             legend='$h_{11} = $ num_cp',\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h11 + coef_h11 * x,\n",
    "             fmt='r--',\n",
    "             axis=0,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h11[0], coef_h11[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.fplot2D(data=num_cp_test,\n",
    "             function=lambda x: interc_h21 + coef_h21 * x,\n",
    "             fmt='r--',\n",
    "             axis=1,\n",
    "             legend='best fit: {:.2f} + ({:.2f}) x num_cp'.format(interc_h21[0], coef_h21[0]),\n",
    "             xlabel='num_cp (test set)',\n",
    "             ylabel='$h_{11}$',\n",
    "             linewidth=0.5\n",
    "            )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lin_svr_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lin_svr_num_cp_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES ONLY     #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES ONLY\\n')\n",
    "\n",
    "estimator.fit(feat_h11_nopca_train, h11_train) #------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_nopca_train, h21_train) #------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lin_svr_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lin_svr_nopca_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES AND PCA  #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES AND PCA\\n')\n",
    "\n",
    "estimator.fit(feat_h11_pca_train, h11_train) #--------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_pca_train, h21_train) #--------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'lin_svr_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'lin_svr_pca_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)\n",
    "\n",
    "We then consider a variation on the previous algorithm introducing a kernel function to compute the distance between the feature points and the landmarks. In this case we will also try to compare the results with [_Bull et al._](https://arxiv.org/abs/1806.03121). The hyperparameter space is:\n",
    "\n",
    "- `gamma` $\\in \\left[ 10^{-3}, 10^3 \\right]$,\n",
    "- `epsilon` $\\in \\left[ 10^{-2}, 10^2 \\right]$ (the $\\epsilon$ parameter for the penalty computation),\n",
    "- `C` $\\in \\left[ 10^{-3}, 10^2 \\right]$ (the regularization parameter),\n",
    "- `shrinking` $\\in \\lbrace 0, 1 \\rbrace$ (whether to use shrinking heuristic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm      import SVR\n",
    "from skopt            import BayesSearchCV\n",
    "from skopt.space      import Integer, Real, Categorical\n",
    "from sklearn.metrics  import make_scorer\n",
    "from mltools.libscore import accuracy, Score, ViewCV\n",
    "from mltools.libplot  import Plot\n",
    "\n",
    "log.info('Trainining svr (Gaussian kernel)...')\n",
    "\n",
    "rounding      = np.rint #---------------------------------------------------------- choose a rounding function\n",
    "n_iter        = 100 #-------------------------------------------------------------- the number of iteration of the Bayes search\n",
    "search_params = {'shrinking': Integer(0, 1),\n",
    "                 'epsilon':   Real(1.0e-2, 1.0e2, prior='log-uniform'),\n",
    "                 'C':         Real(1.0e-3, 1.0e2, prior='log-uniform'),\n",
    "                 'gamma':     Real(1.0e-3, 1.0e3, prior='log-uniform')\n",
    "                } #---------------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(SVR(kernel='rbf', max_iter=1e5), #------------------- choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #------------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# MATRIX                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nMATRIX\\n')\n",
    "\n",
    "estimator.fit(matrix_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(matrix_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'svr_mat_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'svr_mat_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# NUM_CP                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nNUM_CP\\n')\n",
    "\n",
    "estimator.fit(num_cp_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(num_cp_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'svr_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'svr_num_cp_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES ONLY     #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES ONLY\\n')\n",
    "\n",
    "estimator.fit(feat_h11_nopca_train, h11_train) #------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_nopca_train, h21_train) #------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'svr_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'svr_nopca_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES AND PCA  #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES AND PCA\\n')\n",
    "\n",
    "estimator.fit(feat_h11_pca_train, h11_train) #--------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_pca_train, h21_train) #--------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'svr_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'svr_pca_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "\n",
    "We then move to the family of decision trees algorithms and train a random forest of trees on the dataset. Contrary to the preanalysis, in this case we are interested in prediction a we will perform a careful optimization of the parameters. In this case the hyperparameter space we explore is:\n",
    "\n",
    "- `n_estimators` $\\in \\left[ 10, 10^3 \\right]$,\n",
    "- `criterion` $\\in \\lbrace mse, mae \\rbrace$,\n",
    "- `max_depth` $\\in \\left[ 2, 100 \\right]$,\n",
    "- `min_samples_split` $\\in \\left[ 2, 100 \\right]$,\n",
    "- `min_samples_leaf` $\\in \\left[ 1, 100 \\right]$,\n",
    "- `min_weight_fraction_leaf` $\\in \\left[ 0, 1 \\right]$,\n",
    "- `max_leaf_nodes` $\\in \\left[ 1, 100 \\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from skopt            import BayesSearchCV\n",
    "from skopt.space      import Integer, Real, Categorical\n",
    "from sklearn.metrics  import make_scorer\n",
    "from mltools.libscore import accuracy, Score, ViewCV\n",
    "from mltools.libplot  import Plot\n",
    "\n",
    "log.info('Trainining random forest...')\n",
    "\n",
    "rounding      = np.floor #------------------------------------------------------------------- choose a rounding function\n",
    "n_iter        = 100 #------------------------------------------------------------------------ the number of iteration of the Bayes search\n",
    "search_params = {'n_estimators':             Integer(1.0e1, 1.0e3, prior='log-uniform'),\n",
    "                 'max_depth':                Integer(2, 100, prior='uniform'),\n",
    "                 'min_samples_split':        Integer(2, 100, prior='uniform'),\n",
    "                 'min_samples_leaf':         Integer(1, 100, prior='uniform'),\n",
    "                 'max_leaf_nodes':           Integer(1, 100, prior='uniform'),\n",
    "                 'min_weight_fraction_leaf': Real(0.0, 1.0, prior='uniform'),\n",
    "                 'criterion':                Categorical(['mse', 'mae'])\n",
    "                } #-------------------------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(RandomForestRegressor(random_state=RAND), #-------------------- choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #----------------------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# MATRIX                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nMATRIX\\n')\n",
    "\n",
    "estimator.fit(matrix_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(matrix_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'rnd_for_mat_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'rnd_for_mat_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# NUM_CP                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nNUM_CP\\n')\n",
    "\n",
    "estimator.fit(num_cp_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(num_cp_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'rnd_for_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'rnd_for_num_cp_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES ONLY     #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES ONLY\\n')\n",
    "\n",
    "estimator.fit(feat_h11_nopca_train, h11_train) #------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_nopca_train, h21_train) #------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'rnd_for_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'rnd_for_nopca_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES AND PCA  #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES AND PCA\\n')\n",
    "\n",
    "estimator.fit(feat_h11_pca_train, h11_train) #--------------------------------------------------- fit the estimator to h11\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_pca_train, h21_train) #--------------------------------------------------- fit the estimator to h21\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=3) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'rnd_for_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'rnd_for_pca_error.pdf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Gradient Boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)\n",
    "\n",
    "A different approach to decision trees is given by the **gradient boosting** procedure, which optimizes every step of the minimization of the loss function using data from the previous run. In this case we consider the hyperparameter space similar to the random forest:\n",
    "\n",
    "- `loss` $\\in \\lbrace ls, lad, huber \\rbrace$,\n",
    "- `alpha` $\\in \\left[ 0.1, 0.99 \\right]$\n",
    "- `learning_rate` $\\in \\left[ 10^{-4}, 10 \\right]$,\n",
    "- `n_estimators` $\\in \\left[ 10, 10^3 \\right]$,\n",
    "- `subsample` $\\in \\left[ 0.0, 1.0 \\right]$,\n",
    "- `criterion` $\\in \\lbrace friedman\\_mse, mae \\rbrace$,\n",
    "- `min_samples_split` $\\in \\left[ 2, 100 \\right]$,\n",
    "- `min_weight_fraction_leaf` $\\in \\left[ 0, 1 \\right]$,\n",
    "- `max_depth` $\\in \\left[ 2, 100 \\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from skopt            import BayesSearchCV\n",
    "from skopt.space      import Integer, Real, Categorical\n",
    "from sklearn.metrics  import make_scorer\n",
    "from mltools.libscore import accuracy, Score, ViewCV\n",
    "from mltools.libplot  import Plot\n",
    "\n",
    "log.info('Trainining gradient boosting...')\n",
    "\n",
    "rounding      = np.floor #------------------------------------------------------------------- choose a rounding function\n",
    "n_iter        = 100 #------------------------------------------------------------------------ the number of iteration of the Bayes search\n",
    "search_params = {'n_estimators':             Integer(1.0e1, 1.0e3, prior='log-uniform'),\n",
    "                 'max_depth':                Integer(2, 100, prior='uniform'),\n",
    "                 'min_samples_split':        Integer(2, 100, prior='uniform'),\n",
    "                 'learning_rate':            Real(1.0e-4, 1.0e1, prior='log-uniform'),\n",
    "                 'alpha':                    Real(0.0, 1.0, prior='uniform'),\n",
    "                 'min_weight_fraction_leaf': Real(0.0, 1.0, prior='uniform'),\n",
    "                 'subsample':                Real(0.0, 1.0, prior='uniform'),\n",
    "                 'criterion':                Categorical(['friedman_mse', 'mae']),\n",
    "                 'loss':                     Categorical(['ls', 'lad', 'huber'])\n",
    "                } #-------------------------------------------------------------------------- define the hyperparameter optimization space\n",
    "estimator     = BayesSearchCV(GradientBoostingRegressor(random_state=RAND), #---------------- choose the base estimator\n",
    "                              search_spaces=search_params,\n",
    "                              scoring=make_scorer(accuracy,\n",
    "                                                  greater_is_better=True,\n",
    "                                                  rounding=rounding\n",
    "                                                 ), #----------------------------------------- create a custom scoring function (use accuracy after rounding)\n",
    "                              n_jobs=n_jobs,\n",
    "                              refit=True,\n",
    "                              cv=cv\n",
    "                             )\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# MATRIX                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nMATRIX\\n')\n",
    "\n",
    "estimator.fit(matrix_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "loss_h11 = estimator.best_estimator_.train_score_ #---------------------------------------------- get the loss function\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(matrix_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "loss_h21 = estimator.best_estimator_.train_score_ #---------------------------------------------- get the loss function\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(matrix_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=4) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.series2D(loss_h11,\n",
    "              axis=3,\n",
    "              title='Loss Function',\n",
    "              xlabel='boosting rounds',\n",
    "              ylabel='loss',\n",
    "              legend='$h_{11}$',\n",
    "              binstep=3\n",
    "             )\n",
    "plot.series2D(loss_h21,\n",
    "              axis=3,\n",
    "              title='Loss Function',\n",
    "              xlabel='boosting rounds',\n",
    "              ylabel='loss',\n",
    "              legend='$h_{21}$',\n",
    "              binstep=3\n",
    "             )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'grd_boost_mat_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'grd_boost_mat_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# NUM_CP                       #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nNUM_CP\\n')\n",
    "\n",
    "estimator.fit(num_cp_train, h11_train) #--------------------------------------------------------- fit the estimator to h11\n",
    "loss_h11 = estimator.best_estimator_.train_score_ #---------------------------------------------- get the loss function\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(num_cp_train, h21_train) #--------------------------------------------------------- fit the estimator to h21\n",
    "loss_h21 = estimator.best_estimator_.train_score_ #---------------------------------------------- get the loss function\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(num_cp_test) #----------------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=4) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=3\n",
    "           )\n",
    "\n",
    "plot.series2D(loss_h11,\n",
    "              axis=3,\n",
    "              title='Loss Function',\n",
    "              xlabel='boosting rounds',\n",
    "              ylabel='loss',\n",
    "              legend='$h_{11}$',\n",
    "              binstep=3\n",
    "             )\n",
    "plot.series2D(loss_h21,\n",
    "              axis=3,\n",
    "              title='Loss Function',\n",
    "              xlabel='boosting rounds',\n",
    "              ylabel='loss',\n",
    "              legend='$h_{21}$',\n",
    "              binstep=3\n",
    "             )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'grd_boost_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'grd_boost_num_cp_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES ONLY     #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES ONLY\\n')\n",
    "\n",
    "estimator.fit(feat_h11_nopca_train, h11_train) #------------------------------------------------- fit the estimator to h11\n",
    "loss_h11 = estimator.best_estimator_.train_score_ #---------------------------------------------- get the loss function\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_nopca_train, h21_train) #------------------------------------------------- fit the estimator to h21\n",
    "loss_h21 = estimator.best_estimator_.train_score_ #---------------------------------------------- get the loss function\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_nopca_test) #--------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=4) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.series2D(loss_h11,\n",
    "              axis=3,\n",
    "              title='Loss Function',\n",
    "              xlabel='boosting rounds',\n",
    "              ylabel='loss',\n",
    "              legend='$h_{11}$',\n",
    "              binstep=3\n",
    "             )\n",
    "plot.series2D(loss_h21,\n",
    "              axis=3,\n",
    "              title='Loss Function',\n",
    "              xlabel='boosting rounds',\n",
    "              ylabel='loss',\n",
    "              legend='$h_{21}$',\n",
    "              binstep=3\n",
    "             )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'grd_boost_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'grd_boost_nopca_error.pdf')))\n",
    "\n",
    "################################\n",
    "#                              #\n",
    "# ENGINEERED FEATURES AND PCA  #\n",
    "#                              #\n",
    "################################\n",
    "print('\\nENGINEERED FEATURES AND PCA\\n')\n",
    "\n",
    "estimator.fit(feat_h11_pca_train, h11_train) #--------------------------------------------------- fit the estimator to h11\n",
    "loss_h11 = estimator.best_estimator_.train_score_ #---------------------------------------------- get the loss function\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h11:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h11   = estimator.best_estimator_.predict(feat_h11_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h11  = Score(y_true=h11_test, y_pred=preds_h11, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h11.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "estimator.fit(feat_h21_pca_train, h21_train) #--------------------------------------------------- fit the estimator to h21\n",
    "loss_h21 = estimator.best_estimator_.train_score_ #---------------------------------------------- get the loss function\n",
    "\n",
    "cv_score = ViewCV(estimator) #------------------------------------------------------------------- display CV scores\n",
    "print('\\nBest parameters for h21:\\n')\n",
    "pretty(cv_score.best_parameters)\n",
    "print('\\nAccuracy of the cross-validation: {:.3f}% ± {:.3f}%'.format(cv_score.test_mean()*100,\n",
    "                                                                     cv_score.test_std()*100\n",
    "                                                                    ) #-------------------------- print CV accuracy\n",
    "     )\n",
    "\n",
    "preds_h21   = estimator.best_estimator_.predict(feat_h21_pca_test) #----------------------------- compute predictions for h11\n",
    "pred_score_h21  = Score(y_true=h21_test, y_pred=preds_h21, rounding=rounding)\n",
    "print('Accuracy of the predictions: {:.3f}%'.format(pred_score_h21.accuracy()*100)) #------------ print test accuracy\n",
    "\n",
    "plot = Plot(rows=1, columns=4) #----------------------------------------------------------------- plot the comparison of the predictions\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h11_test))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h11)))).T,\n",
    "               axis=0,\n",
    "               title='Comparison of the Predictions for $h_{11}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{11}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, h21_test))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='real values',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "plot.scatter2D(np.array(list(get_counts(num_cp_test, rounding(preds_h21)))).T,\n",
    "               axis=1,\n",
    "               title='Comparison of the Predictions for $h_{21}$',\n",
    "               legend='predictions',\n",
    "               xlabel='num_cp (test set)',\n",
    "               ylabel='$h_{21}$',\n",
    "               colour=False,\n",
    "               alpha=0.65\n",
    "              )\n",
    "\n",
    "plot.hist2D(pred_score_h11.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{11}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "plot.hist2D(pred_score_h21.error(),\n",
    "            axis=2,\n",
    "            title='Distance of the Predictions from the Real Value',\n",
    "            legend='$h_{21}$',\n",
    "            xlabel='error difference',\n",
    "            ylabel='#',\n",
    "            binstep=2\n",
    "           )\n",
    "\n",
    "plot.series2D(loss_h11,\n",
    "              axis=3,\n",
    "              title='Loss Function',\n",
    "              xlabel='boosting rounds',\n",
    "              ylabel='loss',\n",
    "              legend='$h_{11}$',\n",
    "              binstep=3\n",
    "             )\n",
    "plot.series2D(loss_h21,\n",
    "              axis=3,\n",
    "              title='Loss Function',\n",
    "              xlabel='boosting rounds',\n",
    "              ylabel='loss',\n",
    "              legend='$h_{21}$',\n",
    "              binstep=3\n",
    "             )\n",
    "\n",
    "plot.save_and_close(path.join(IMG_PATH, 'grd_boost_num_cp_error'))\n",
    "log.debug('Plot saved to {}.'.format(path.join(IMG_PATH, 'grd_boost_pca_error.pdf')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
